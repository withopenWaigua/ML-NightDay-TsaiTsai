{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/withopenWaigua/ML-NightDay-TsaiTsai/blob/main/Lesson_10_2_%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95_%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%EF%BC%881223%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb8a721a-8900-4328-a607-528e47641244",
      "metadata": {
        "id": "cb8a721a-8900-4328-a607-528e47641244"
      },
      "source": [
        "# 超参数优化 - 贝叶斯优化方法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ece3d47a-5c9c-4991-a65f-05d274f7462b",
      "metadata": {
        "id": "ece3d47a-5c9c-4991-a65f-05d274f7462b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib as mlp\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import re, pip, conda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75fe5e5b-25a1-4fbf-b8a5-c6217e02528f",
      "metadata": {
        "id": "75fe5e5b-25a1-4fbf-b8a5-c6217e02528f",
        "outputId": "3fed1447-a813-425b-c72f-6637a6571faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sklearn 1.0.1\n",
            "matplotlib 3.4.3\n",
            "numpy 1.21.4\n",
            "pandas 1.3.4\n",
            "seaborn 0.11.2\n",
            "pip 21.3.1\n",
            "conda 4.11.0\n"
          ]
        }
      ],
      "source": [
        "for package in [sklearn,mlp,np,pd,sns,pip,conda]:\n",
        "    print(re.findall(\"([^']*)\",str(package))[2],package.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "994732af-b741-4370-9824-ad29693e1cc4",
      "metadata": {
        "id": "994732af-b741-4370-9824-ad29693e1cc4"
      },
      "outputs": [],
      "source": [
        "#pip install --upgrade scikit-learn\n",
        "#conda update scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f961696-9e11-406e-bcbf-20b222e50078",
      "metadata": {
        "id": "3f961696-9e11-406e-bcbf-20b222e50078"
      },
      "source": [
        "**目录**\n",
        "\n",
        "一 贝叶斯优化基础方法<br>\n",
        "&emsp; 1 贝叶斯优化的基本流程<br>\n",
        "&emsp; 2 贝叶斯优化用于HPO<br>\n",
        "二 贝叶斯优化的实现<br>\n",
        "&emsp; 1 基于Bayes_opt实现GP优化<br>\n",
        "&emsp; 2 基于HyperOpt实现TPE优化<br>\n",
        "&emsp; 3 基于Optuna实现多种贝叶斯优化<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d9f3041-aefb-4e1a-80f3-8ce87f2aa249",
      "metadata": {
        "id": "9d9f3041-aefb-4e1a-80f3-8ce87f2aa249"
      },
      "source": [
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59c72fea-00fb-4a71-8b47-21c79fb348ce",
      "metadata": {
        "tags": [],
        "id": "59c72fea-00fb-4a71-8b47-21c79fb348ce"
      },
      "source": [
        "# 一 贝叶斯优化基础方法"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ee71c0-d70f-4b23-8308-ec2108a9f672",
      "metadata": {
        "id": "c8ee71c0-d70f-4b23-8308-ec2108a9f672"
      },
      "source": [
        "在之前的课程中我们讲解了网格搜索、随机网格搜索与Halving网格搜索，无论具体每种网格搜索的思想如何变化，网格优化都是在一个大参数空间中、尽量对所有点进行验证后再返回最优损失函数值的方法，这一类方法在计算量与计算时间上有着不可避免的缺陷，因此才会有随机、Halving等试图缩短训练时间、让整体网格搜索更加适合于大型数据和大型空间的手段。然而，尽管sklearn在提高网格搜索效率方面做出了种种优化，但上述方法仍然无法在效率和精度上做到双赢，若希望更快速的进行参数搜索、并且搜索出一组泛化能力尽可能强的参数，目前的常见做法还是选用一些带有**先验过程**的调参工具，即一些基于贝叶斯过程调参工具。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d743a92-4be9-4242-aace-0485fa547873",
      "metadata": {
        "id": "5d743a92-4be9-4242-aace-0485fa547873"
      },
      "source": [
        "贝叶斯优化方法是当前超参数优化领域的SOTA手段（State of the Art），可以被认为是当前最为先进的优化框架，它可以被应用于AutoML的各大领域，不止限于超参数搜索HPO的领域，更是可以被用于神经网络架构搜索NAS以及元学习等先进的领域。现代几乎所有在效率和效果上取得优异成果的超参数优化方法都是基于贝叶斯优化的基本理念而形成的，因此贝叶斯优化是整个AutoML中学习的重点。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f18a3e1f-69bf-4ef8-bec4-724a5a5f7f2f",
      "metadata": {
        "id": "f18a3e1f-69bf-4ef8-bec4-724a5a5f7f2f"
      },
      "source": [
        "然而，虽然贝叶斯优化非常强大，但整体的学习难度却非常高。在学习贝叶斯优化之前，学习者不仅需要充分理解机器学习的主要概念和算法、熟悉典型的超参数优化流程，还需要对部分超出微积分、概率论和线性代数的数学知识有所掌握。特别的是，贝叶斯优化算法本身，与贝叶斯优化用于HPO的过程还有区别。**在我们课程有限的时间内，我将重点带大家来看贝叶斯优化用于HPO的核心过程**。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24507e15-4612-45a1-a10f-cee59d604dc1",
      "metadata": {
        "id": "24507e15-4612-45a1-a10f-cee59d604dc1"
      },
      "source": [
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa3a5cea-eb45-4114-8a89-affe6ba23398",
      "metadata": {
        "id": "fa3a5cea-eb45-4114-8a89-affe6ba23398"
      },
      "source": [
        "## 1 贝叶斯优化的基本流程"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b62fb716-fc0b-4ece-878a-b0d9a57385c9",
      "metadata": {
        "tags": [],
        "id": "b62fb716-fc0b-4ece-878a-b0d9a57385c9"
      },
      "source": [
        "首先，我们不理会HPO的问题，先来看待下面的例子。假设现在我们知道一个函数$f(x)$的表达式以及其自变量$x$的定义域，现在，我们希望求解出$x$的取值范围上$f(x)$的最小值，你打算如何求解这个最小值呢？面对这个问题，无论是从单纯的数学理论角度，还是从机器学习的角度，我们都已经见过好几个通俗的思路：\n",
        "\n",
        "- 1 我们可以对$f(x)$求导、令其一阶导数为0来求解其最小值\n",
        "\n",
        "> **<font color=\"red\">函数$f(x)$可微，且微分方程可以直接被求解</font>**<br>\n",
        "\n",
        "- 2 我们可以通过梯度下降等优化方法迭代出$f(x)$的最小值\n",
        "\n",
        "> **<font color=\"red\">函数$f(x)$可微，且函数本身为凸函数</font>**<br>\n",
        "\n",
        "- 3 我们将全域的$x$带入$f(x)$计算出所有可能的结果，再找出最小值\n",
        "\n",
        "> **<font color=\"red\">函数$f(x)$相对不复杂、自变量维度相对低、计算量可以承受</font>**<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30182363-d1c4-46f1-9da1-84627204ba86",
      "metadata": {
        "id": "30182363-d1c4-46f1-9da1-84627204ba86"
      },
      "source": [
        "当我们知道函数$f(x)$的表达式时，以上方法常常能够有效，但每个方法都有自己的前提条件。**假设现在函数$f(x)$是一个平滑均匀的函数，但它异常复杂、且不可微，我们无法使用上述三种方法中的任意一种方法求解**，但我们还是想求解其最小值，可以怎么办呢？由于函数异常复杂，带入任意$x$计算的所需的时间很长，所以我们不太可能将全域$x$都带入进行计算，但我们还是可以从中随机抽样部分观测点来观察整个函数可能存在的趋势。于是我们选择在$x$的定义域上随机选择了4个点，并将4个点带入$f(x)$进行计算，得到了如下结果：\n",
        "\n",
        "![01](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/01.png?versionId=CAEQIBiBgIClje2V7xciIGQyMTFmYWMzZjg3MzRiZGE5ZTA5Y2M0MTc0NDQ3M2Ez)\n",
        "\n",
        "好了，现在有了这4个观测值，你能告诉我$f(x)$的最小值在哪里吗？你认为最小值点可能在哪里呢？大部分人会倾向于认为，最小值点可能非常接近于已观测出4个$f(x)$值中最小的那个值，但也有许多人不这么认为。当我们有了4个观测值，并且知道我们的函数时相对均匀、平滑的函数，那我们可能对函数的整体分布有如下猜测：\n",
        "\n",
        "![02](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/02.png?versionId=CAEQIBiBgICGjO2V7xciIDZiZWI4ZTg1NjBkZTQwMmFiOGJiOGZiMTk0ZTEzZTdh)\n",
        "\n",
        "当我们对函数整体分布有一个猜测时，这个分布上一定会存在该函数的最小值。同时，不同的人可能对函数的整体分布有不同的猜测，不同猜测下对应的最小值也是不同的。\n",
        "\n",
        "![03](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/03.png?versionId=CAEQIBiBgICEjO2V7xciIDNjYTM4ODY0MjQ0NTQ4MjhiYTA0NzFjOWRjMjFiYjM1)\n",
        "\n",
        "![04](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/04.png?versionId=CAEQIBiBgMCQjO2V7xciIGM5NTQ5MjlhM2UwNTQ3NzA4NzllZGM0YzQyNDczZWI3)\n",
        "\n",
        "现在，假设我们邀请了数万个人对该问题做出猜测，每个人所猜测的曲线如下图所示。不难发现，在观测点的附近，每个人猜测的函数值差距不大，但是在远离远侧点的地方，每个人猜测的函数值就高度不一致了。这也是当然的，因为观测点之间函数的分布如何完全是未知的，并且该分布离观测点越远时，我们越不确定真正的函数值在哪里，因此人们猜测的函数值的范围非常巨大。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f9575a-8ae1-49b1-a905-6db71df03440",
      "metadata": {
        "id": "d4f9575a-8ae1-49b1-a905-6db71df03440"
      },
      "source": [
        "![05](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/05.png?versionId=CAEQIBiBgICQjO2V7xciIDY5YTdiYzVhNDBlODQ3ZDNiNjNhYmNmN2E5MTBiOTA2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4ac04f-ef8d-4ecc-a99d-f6a9e2f9fe7e",
      "metadata": {
        "id": "7a4ac04f-ef8d-4ecc-a99d-f6a9e2f9fe7e"
      },
      "outputs": [],
      "source": [
        "[0,1] - 100个小区间\n",
        "\n",
        "[0,0.01] n1\n",
        "[0.01,0.02] n2\n",
        "[0.02,0.03] n3\n",
        "...\n",
        "[0.99,1] n100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44c957b6-5b5d-49a8-91b5-45564148bdcd",
      "metadata": {
        "id": "44c957b6-5b5d-49a8-91b5-45564148bdcd"
      },
      "source": [
        "现在，我们将所有猜测求均值，并将任意均值周围的潜在函数值所在的区域用色块表示，可以得到一条所有人猜测的平均曲线。不难发现，色块所覆盖的范围其实就是大家猜测的函数值的上界和下界，而任意$x$所对应的上下界差异越大，表示人们对函数上该位置的猜测值的越不确定。**因此上下界差异可以衡量人们对该观测点的置信度，色块范围越大，置信度越低**。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72fff34d-f270-43fd-a9c8-ac25fffb73ef",
      "metadata": {
        "id": "72fff34d-f270-43fd-a9c8-ac25fffb73ef"
      },
      "source": [
        "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/06.png?versionId=CAEQIBiBgMC_i.2V7xciIGM4MDJiNTI2ZmY2NDQxYWI5ZDdkZTkwOGQzY2Y4ZWVk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2747ca40-0a39-4596-948e-707c6747dc38",
      "metadata": {
        "id": "2747ca40-0a39-4596-948e-707c6747dc38"
      },
      "source": [
        "在观测点周围，置信度总是很高的，远离观测点的地方，置信度总是很低，所以如果我们能够在置信度很低的地方补充一个实际的观测点，我们就可以很快将众人的猜测统一起来。以下图为例，当我们在置信度很低的区间内取一个实际观测值时，围绕该区间的“猜测”会立刻变得集中，该区间内的置信度会大幅升高。\n",
        "\n",
        "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/08.png)\n",
        "\n",
        "当整个函数上的置信度都非常高时，我们可以说我们得出了一条与真实的$f(x)$曲线高度相似的曲线$f^*$，次数我们就可以将$f^*$的最小值当作真实$f(x)$的最小值来看待。自然，如果估计越准确，$f^*$越接近$f(x)$，则$f^*$的最小值也会越接近于$f(x)$的真实最小值。那如何才能够让$f^*$更接近$f(x)$呢？根据我们刚才提升置信度的过程，很明显——观测点越多，我们估计出的曲线会越接近真实的$f(x)$。然而，由于计算量有限，我们每次进行观测时都要非常谨慎地选择观测点。那现在，**如何选择观测点才能够最大程度地帮助我们估计出$f(x)$的最小值呢？**\n",
        "\n",
        "有非常多的方法，其中最简单的手段是使用**最小值出现的频数**进行判断。由于不同的人对函数的整体分布有不同的猜测，不同猜测下对应的最小值也是不同的，根据每个人猜测的函数结果，我们在$X$轴上将定义域区间均匀划分为100个小区间，如果有某个猜测的最小值落在其中一个区间中，我们就对该区间进行计数（这个过程跟对离散型变量绘制直方图的过程完全一致）。当有数万个人进行猜测之后，我们同时也绘制了基于$X$轴上不同区间的频数图，频数越高，说明猜测最小值在该区间内的人越多，反之则说明该猜测最小值在该区间内的人越少。**该频数一定程度上反馈出最小值出现的概率，频数越高的区间，函数真正的最小值出现的概率越高**。\n",
        "\n",
        "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/09.png)\n",
        "\n",
        "当我们将$X$轴上的区间划分得足够细后，绘制出的频数图可以变成概率密度曲线，**曲线的最大值所对应的点是$f(x)$的最小值的概率最高**，因此很明显，我们应该将曲线最大值所对应的点确认为下一个观测点。根据图像，我们知道最小值最有可能在的区间就在x=0.7左右的位置。当我们不取新的观测点时，现在$f(x)$上可以获得的可靠的最小值就是x=0.6时的点，但我们如果在x=0.7处取新的观测值，我们就很有可能找到比当前x=0.6的点还要小的$f_{min}$。因此，我们可以就此决定，在x=0.7处进行观测。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8326138-04bb-4bac-ad1f-00a09e189c61",
      "metadata": {
        "id": "a8326138-04bb-4bac-ad1f-00a09e189c61"
      },
      "source": [
        "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/07.png?versionId=CAEQIBiBgMC9je2V7xciIDU3MDA3Y2Q4NjlmMDQ4OTliZTNlNTQ2ZWM3YTZlOTE0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96e7dfe8-0645-44bc-9f3c-49363e99a63d",
      "metadata": {
        "id": "96e7dfe8-0645-44bc-9f3c-49363e99a63d"
      },
      "source": [
        "当我们在x=0.7处取出观测值之后，我们就有了5个已知的观测点。现在，我们再让数万人根据5个已知的观测点对整体函数分布进行猜测，猜测完毕之后再计算当前最小值频数最高的区间，然后再取新的观测点对$f(x)$进行计算。当允许的计算次数被用完之后（比如，500次），整个估计也就停止了。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb3896aa-0e3e-4df1-a1dd-d4ba9096d7a8",
      "metadata": {
        "id": "bb3896aa-0e3e-4df1-a1dd-d4ba9096d7a8"
      },
      "source": [
        "你发现了吗？在这个过程当中，我们其实在不断地优化我们对目标函数$f(x)$的估计，虽然没有对$f(x)$进行全部定义域上的计算，也没有找到最终确定一定是$f(x)$分布的曲线，但是随着我们观测的点越来越多，我们对函数的估计是越来越准确的，因此也有越来越大的可能性可以估计出$f(x)$真正的最小值。**这个优化的过程，就是贝叶斯优化**。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ea53d4-8f4c-4b76-9668-d62f3940c254",
      "metadata": {
        "id": "d5ea53d4-8f4c-4b76-9668-d62f3940c254"
      },
      "source": [
        "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/08.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a98e7825-618a-4741-9dd2-928dcde03ea5",
      "metadata": {
        "id": "a98e7825-618a-4741-9dd2-928dcde03ea5"
      },
      "source": [
        "## 2 贝叶斯优化用于HPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628635aa-93d0-4ffa-9fa4-89f86a9a67e7",
      "metadata": {
        "id": "628635aa-93d0-4ffa-9fa4-89f86a9a67e7"
      },
      "source": [
        "------\n",
        "\n",
        "在贝叶斯优化的数学过程当中，我们主要执行以下几个步骤：\n",
        "\n",
        "- 1 定义需要估计的$f(x)$以及$x$的定义域<br>\n",
        "\n",
        "- 2 取出有限的n个$x$上的值，求解出这些$x$对应的$f(x)$（求解观测值）<br>\n",
        "\n",
        "- 3 根据有限的观测值，对函数进行估计（该假设被称为贝叶斯优化中的先验知识），得出该估计$f^*$上的目标值（最大值或最小值）<br>\n",
        "\n",
        "- 4 定义某种规则，以确定下一个需要计算的观测点\n",
        "\n",
        "并持续在2-4步骤中进行循环，直到假设分布上的目标值达到我们的标准，或者所有计算资源被用完为止（例如，最多观测m次，或最多允许运行t分钟）。\n",
        "\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e987ae6-cf43-4ca1-b25a-10a61c9c8106",
      "metadata": {
        "id": "7e987ae6-cf43-4ca1-b25a-10a61c9c8106"
      },
      "source": [
        "以上流程又被称为序贯模型优化（SMBO），是最为经典的贝叶斯优化方法。在实际的运算过程当中，尤其是超参数优化的过程当中，有以下具体细节需要注意： \n",
        "\n",
        "- 当贝叶斯优化不被用于HPO时，一般$f(x)$可以是完全的黑盒函数（black box function，也译作黑箱函数，即只知道$x$与$f(x)$的对应关系，却丝毫不知道函数内部规律、同时也不能写出具体表达式的一类函数），因此贝叶斯优化也被认为是可以作用于黑盒函数估计的一类经典方法。但在HPO过程当中，需要定义的$f(x)$一般是交叉验证的结果/损失函数的结果，而我们往往非常清楚损失函数的表达式，只是我们不了解损失函数内部的具体规律，因此HPO中的$f(x)$不能算是严格意义上的黑盒函数。\n",
        "\n",
        "- 在HPO中，自变量$x$就是超参数空间。在上述二维图像表示中，$x$为一维的，但在实际进行优化时，超参数空间往往是高维且极度复杂的空间。\n",
        "\n",
        "- 最初的观测值数量n、以及最终可以取到的最大观测数量m都是贝叶斯优化的超参数，最大观测数量m也决定了整个贝叶斯优化的迭代次数。\n",
        "\n",
        "- 在第3步中，根据有限的观测值、对函数分布进行估计的工具被称为**概率代理模型**（Probability Surrogate model），毕竟在数学计算中我们并不能真的邀请数万人对我们的观测点进行连线。**这些概率代理模型自带某些假设，他们可以根据廖廖数个观测点估计出目标函数的分布$f^*$（包括$f^*$上每个点的取值以及该点对应的置信度）**。在实际使用时，概率代理模型往往是一些强大的算法，最常见的比如高斯过程、高斯混合模型等等。传统数学推导中往往使用高斯过程，但现在最普及的优化库中基本都默认使用基于高斯混合模型的TPE过程。\n",
        "\n",
        "- 在第4步中用来确定下一个观测点的规则被称为**采集函数**（Aquisition Function），采集函数衡量观测点对拟合$f^*$所产生的影响，并选取影响最大的点执行下一步观测，因此我们往往关注**采集函数值最大的点**。最常见的采集函数主要是概率增量PI（Probability of improvement，比如我们计算的频数）、期望增量（Expectation Improvement）、置信度上界（Upper Confidence Bound）、信息熵（Entropy）等等。上方gif图像当中展示了PI、UCB以及EI。其中大部分优化库中默认使用期望增量。\n",
        "\n",
        "在HPO中使用贝叶斯优化时，我们常常会看见下面的图像，这张图像表现了贝叶斯优化的全部基本元素，我们的目标就是在采集函数指导下，让$f^*$尽量接近$f(x)$。\n",
        "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021MachineLearning/Ensembles/Public/11.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1074ef91-0638-48c3-9f97-dec975d22824",
      "metadata": {
        "id": "1074ef91-0638-48c3-9f97-dec975d22824"
      },
      "source": [
        "现在我们已经了解贝叶斯优化的基本流程。与许多算法一样，基础流程足以支撑我们使用已经搭建好的优化库进行超参数优化了，即便我们没有对优化原理的每个细节都了如指掌，我们也可以通过实验反馈出的结果来直接判断是否应该调整我们的代码。接下来，我们会先学习如何应用贝叶斯优化的各类库实现不同的贝叶斯优化算法。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aba4c47f-db0b-4380-9232-3c48f80a9157",
      "metadata": {
        "id": "aba4c47f-db0b-4380-9232-3c48f80a9157"
      },
      "source": [
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ab201e-66cb-450c-8194-7d442cbafd0e",
      "metadata": {
        "tags": [],
        "id": "81ab201e-66cb-450c-8194-7d442cbafd0e"
      },
      "source": [
        "# 二 贝叶斯优化的实现"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d1f6b4c-17d4-45cf-8bcb-17778038fb26",
      "metadata": {
        "id": "5d1f6b4c-17d4-45cf-8bcb-17778038fb26"
      },
      "source": [
        "贝叶斯优化是当今黑盒函数估计领域最为先进和经典的方法，在同一套序贯模型下使用不同的代理模型以及采集函数、还可以发展出更多更先进的贝叶斯优化改进版算法，因此，贝叶斯优化的其算法本身就多如繁星，实现各种不同种类的贝叶斯优化的库也是琳琅满目，几乎任意一个专业用于超参数优化的工具库都会包含贝叶斯优化的内容。我们可以在以下页面找到大量可以实现贝叶斯优化方法的HPO库：https://www.automl.org/automl/hpo-packages/ ，其中大部分库都是由独立团队开发和维护，因此不同的库之间之间的优劣、性格、功能都有很大的差异。在课程中，我们将介绍如下三个可以实现贝叶斯优化的库：`bayesian-optimization`，`hyperopt`，`optuna`。\n",
        "\n",
        "|HPO库|优劣评价|推荐指数|\n",
        "|-|-|-|\n",
        "|**bayes_opt**|✅实现基于高斯过程的贝叶斯优化<br>✅当参数空间由大量连续型参数构成时<br><br>⛔包含大量离散型参数时避免使用<br>⛔算力/时间稀缺时避免使用|⭐⭐|\n",
        "|**hyperopt**|✅实现基于TPE的贝叶斯优化<br>✅支持各类提效工具<br>✅进度条清晰，展示美观，较少怪异警告或报错<br>✅可推广/拓展至深度学习领域<br><br>⛔不支持基于高斯过程的贝叶斯优化<br>⛔代码限制多、较为复杂，灵活性较差|⭐⭐⭐⭐|\n",
        "|**optuna**|✅（可能需结合其他库）实现基于各类算法的贝叶斯优化<br>✅代码最简洁，同时具备一定的灵活性<br>✅可推广/拓展至深度学习领域<br><br>⛔非关键性功能维护不佳，有怪异警告与报错|⭐⭐⭐⭐|"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2020b18f-f1df-4b54-97eb-f3c7576e3c92",
      "metadata": {
        "id": "2020b18f-f1df-4b54-97eb-f3c7576e3c92"
      },
      "source": [
        "注意，以上三个库<font color=\"red\">**都不支持基于Python环境的并行或加速**</font>，大多数优化算法库只能够支持基于数据库（如MangoDB，mySQL）的并行或加速，但以上库都可以被部署在分布式计算平台。\n",
        "\n",
        "三个库极其辅助包的安装方法分别如下，使用pip或conda安装时注意关闭梯子。\n",
        "\n",
        "- Bayes_opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05a436f0-ac5a-4bf9-b51c-c83692a62fbb",
      "metadata": {
        "id": "05a436f0-ac5a-4bf9-b51c-c83692a62fbb"
      },
      "outputs": [],
      "source": [
        "#!pip install bayesian-optimization\n",
        "#!conda install -c conda-forge bayesian-optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb484660-eb6b-4649-86b5-56e1400fefa3",
      "metadata": {
        "id": "bb484660-eb6b-4649-86b5-56e1400fefa3"
      },
      "source": [
        "- Hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df08313-85d8-40f7-8ef0-9dbf8226e525",
      "metadata": {
        "id": "1df08313-85d8-40f7-8ef0-9dbf8226e525"
      },
      "outputs": [],
      "source": [
        "#!pip install hyperopt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1e301a3-821e-4268-a88a-b3d9a2a6785f",
      "metadata": {
        "id": "c1e301a3-821e-4268-a88a-b3d9a2a6785f"
      },
      "source": [
        "- Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4283c05d-066f-465e-9ec2-046558180ee5",
      "metadata": {
        "id": "4283c05d-066f-465e-9ec2-046558180ee5"
      },
      "outputs": [],
      "source": [
        "#!pip install optuna\n",
        "#!conda install -c conda-forge optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc863f94-10d9-4b87-9c9c-013fe8bd9dbf",
      "metadata": {
        "id": "fc863f94-10d9-4b87-9c9c-013fe8bd9dbf"
      },
      "source": [
        "- Skopt（作为Optuna辅助包安装，也可单独使用）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f58f2c6c-fcc9-4d7a-bd7d-d6aad75f50ce",
      "metadata": {
        "id": "f58f2c6c-fcc9-4d7a-bd7d-d6aad75f50ce"
      },
      "outputs": [],
      "source": [
        "#!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "451ac597-9195-4c3c-b719-a04e28ab93d4",
      "metadata": {
        "id": "451ac597-9195-4c3c-b719-a04e28ab93d4"
      },
      "source": [
        "接下来我们会分别使用三个库来实现贝叶斯优化。在课程中，我们依然使用集成算法中的房价数据作为验证数据，并且呈现出我们之前在不同优化方法上得出的结果作为对比。同时，我们将使用与集成算法中完全一致的随机数种子、以及随机森林算法作为被优化的评估器。\n",
        "\n",
        "- **导入库，确认使用数据**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f422db2f-d00c-4e55-a99b-4a0d51d16798",
      "metadata": {
        "id": "f422db2f-d00c-4e55-a99b-4a0d51d16798"
      },
      "outputs": [],
      "source": [
        "#基本工具\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os #修改环境设置\n",
        "\n",
        "#算法/损失/评估指标等\n",
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestRegressor as RFR\n",
        "from sklearn.model_selection import KFold, cross_validate\n",
        "\n",
        "#优化器\n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "import hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials, partial\n",
        "from hyperopt.early_stop import no_progress_loss\n",
        "\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb06475e-93c9-4d48-a393-ce77fa730644",
      "metadata": {
        "id": "cb06475e-93c9-4d48-a393-ce77fa730644"
      },
      "source": [
        "Bayes_opt版本：1.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45cb3295-a649-4b96-8d5c-51fbe69c332b",
      "metadata": {
        "id": "45cb3295-a649-4b96-8d5c-51fbe69c332b",
        "outputId": "3ae58d53-eb26-44c5-cf34-d8daf5f80af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.10.0\n"
          ]
        }
      ],
      "source": [
        "print(optuna.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d93fa6-5451-4e6d-aae6-8a01c2f057d4",
      "metadata": {
        "id": "21d93fa6-5451-4e6d-aae6-8a01c2f057d4",
        "outputId": "cf84e1c0-1525-4518-8c4d-73e16bc91f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2.7\n"
          ]
        }
      ],
      "source": [
        "print(hyperopt.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d75d9f5e-dbcc-4d40-bd87-21c44ba8f0cd",
      "metadata": {
        "id": "d75d9f5e-dbcc-4d40-bd87-21c44ba8f0cd"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(r\"D:\\Pythonwork\\2021ML\\PART 2 Ensembles\\datasets\\House Price\\train_encode.csv\",index_col=0)\n",
        "\n",
        "X = data.iloc[:,:-1]\n",
        "y = data.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c5c303-a97b-4821-b9ae-933fac9be335",
      "metadata": {
        "id": "f0c5c303-a97b-4821-b9ae-933fac9be335",
        "outputId": "d65ab467-c363-4625-f2e6-86023c3eb907"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>住宅类型</th>\n",
              "      <th>住宅区域</th>\n",
              "      <th>街道接触面积(英尺)</th>\n",
              "      <th>住宅面积</th>\n",
              "      <th>街道路面状况</th>\n",
              "      <th>巷子路面状况</th>\n",
              "      <th>住宅形状(大概)</th>\n",
              "      <th>住宅现状</th>\n",
              "      <th>水电气</th>\n",
              "      <th>...</th>\n",
              "      <th>半开放式门廊面积</th>\n",
              "      <th>泳池面积</th>\n",
              "      <th>泳池质量</th>\n",
              "      <th>篱笆质量</th>\n",
              "      <th>其他配置</th>\n",
              "      <th>其他配置的价值</th>\n",
              "      <th>销售月份</th>\n",
              "      <th>销售年份</th>\n",
              "      <th>销售类型</th>\n",
              "      <th>销售状态</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>327.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>498.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>702.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>489.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 80 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Id  住宅类型  住宅区域  街道接触面积(英尺)   住宅面积  街道路面状况  巷子路面状况  住宅形状(大概)  住宅现状  水电气  \\\n",
              "0  0.0   5.0   3.0        36.0  327.0     1.0     0.0       3.0   3.0  0.0   \n",
              "1  1.0   0.0   3.0        51.0  498.0     1.0     0.0       3.0   3.0  0.0   \n",
              "2  2.0   5.0   3.0        39.0  702.0     1.0     0.0       0.0   3.0  0.0   \n",
              "3  3.0   6.0   3.0        31.0  489.0     1.0     0.0       0.0   3.0  0.0   \n",
              "4  4.0   5.0   3.0        55.0  925.0     1.0     0.0       0.0   3.0  0.0   \n",
              "\n",
              "   ...  半开放式门廊面积  泳池面积  泳池质量  篱笆质量  其他配置  其他配置的价值  销售月份  销售年份  销售类型  销售状态  \n",
              "0  ...       0.0   0.0   0.0   0.0   0.0      0.0   1.0   2.0   8.0   4.0  \n",
              "1  ...       0.0   0.0   0.0   0.0   0.0      0.0   4.0   1.0   8.0   4.0  \n",
              "2  ...       0.0   0.0   0.0   0.0   0.0      0.0   8.0   2.0   8.0   4.0  \n",
              "3  ...       0.0   0.0   0.0   0.0   0.0      0.0   1.0   0.0   8.0   0.0  \n",
              "4  ...       0.0   0.0   0.0   0.0   0.0      0.0  11.0   2.0   8.0   4.0  \n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f811913-7675-4896-9b4d-dd9343bab99f",
      "metadata": {
        "id": "1f811913-7675-4896-9b4d-dd9343bab99f",
        "outputId": "709c05eb-5367-4182-fe64-8c4305ea9ded"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1460, 80)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "816d8b14-28a9-41e5-88d1-a2db67e0ccf1",
      "metadata": {
        "id": "816d8b14-28a9-41e5-88d1-a2db67e0ccf1"
      },
      "source": [
        "- **确认该数据集上的历史成果**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbb211e2-a68e-41ab-b8a1-e408f6c69c79",
      "metadata": {
        "id": "cbb211e2-a68e-41ab-b8a1-e408f6c69c79"
      },
      "source": [
        "|HPO方法|默认参数|网格搜索|随机搜索|随机搜索<br>(大空间)|随机搜索<br>(连续型)|\n",
        "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
        "|搜索空间/全域空间|-|1536/1536|800/1536|1536/3000|1536/无限|\n",
        "|运行时间（分钟）|-|6.36|<font color=\"green\">**2.83(↓)**</font>|<font color=\"green\">**3.86(↓)**</font>|3.92|\n",
        "|搜索最优（RMSE）|30571.266|29179.698|29251.284|<font color=\"green\">**29012.905(↓)**</font>|29148.381|\n",
        "|重建最优（RMSE）|-|28572.070|<font color=\"brown\">**28639.969(↑)**</font>|<font color=\"green\">**28346.673(↓)**</font>|28495.682|"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f25d9e42-d246-4749-b9cd-ea021cec006b",
      "metadata": {
        "id": "f25d9e42-d246-4749-b9cd-ea021cec006b"
      },
      "source": [
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7241b3-baf4-4f7b-8243-465421ed6b16",
      "metadata": {
        "tags": [],
        "id": "ae7241b3-baf4-4f7b-8243-465421ed6b16"
      },
      "source": [
        "## 1 基于Bayes_opt实现GP优化"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc57c1d8-1b2c-45a1-b76f-81e0b98799b1",
      "metadata": {
        "tags": [],
        "id": "cc57c1d8-1b2c-45a1-b76f-81e0b98799b1"
      },
      "source": [
        "bayes-optimization是最早开源的贝叶斯优化库之一，也是为数不多至今依然保留着高斯过程优化的优化库。由于开源较早、代码简单，bayes-opt常常出现在论文、竞赛kernels或网络学习材料当中，因此理解Bayes_opt的代码是极其重要的课题。不过，bayes-opt对参数空间的处理方式较为原始，也缺乏相应的提效/监控功能，对算力的要求较高，因此它往往不是我们进行优化时的第一首选库。通常来说，当且仅当我们必须要实现基于高斯过程的贝叶斯优化，且算法的参数空间中带有大量连续型参数时，我们才会优先考虑Bayes_opt库。我们可以在github上找到bayes-optmization的官方文档（https://github.com/fmfn/BayesianOptimization） ，想要进一步了解其基本功能与原理的小伙伴可以进行阅读。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50cd5710-a203-476c-baa0-cc319259023a",
      "metadata": {
        "id": "50cd5710-a203-476c-baa0-cc319259023a"
      },
      "outputs": [],
      "source": [
        "from bayes_opt import BayesianOptimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e5eba6-e79f-4a80-98b1-c7da516a0263",
      "metadata": {
        "id": "34e5eba6-e79f-4a80-98b1-c7da516a0263"
      },
      "source": [
        "- 1 定义目标函数"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3441cc5-ec41-43fe-8349-395aaeeef768",
      "metadata": {
        "id": "d3441cc5-ec41-43fe-8349-395aaeeef768"
      },
      "source": [
        "目标函数的值即$f(x)$的值。贝叶斯优化会计算$f(x)$在不同$x$上的观测值，因此$f(x)$的计算方式需要被明确。在HPO过程中，我们希望能够筛选出令模型泛化能力最大的参数组合，因此$f(x)$应该是损失函数的交叉验证值或者某种评估指标的交叉验证值。**需要注意的是，bayes_opt库存在三个影响目标函数定义的规则**：\n",
        "\n",
        "> **1 目标函数的输入必须是具体的超参数，而不能是整个超参数空间，更不能是数据、算法等超参数以外的元素**，因此在定义目标函数时，我们需要让超参数作为目标函数的输入。<br><br>\n",
        "> **2 超参数的输入值只能是浮点数，不支持整数与字符串**。因此当算法的实际参数需要输入字符串时，该参数不能使用bayes_opt进行调整，当算法的实际参数需要输入整数时，则需要在目标函数中规定参数的类型。<br><br>\n",
        "> **3 bayes_opt只支持寻找$f(x)$的最大值，不支持寻找最小值**。因此当我们定义的目标函数是某种损失时，目标函数的输出需要取负（即，如果使用RMSE，则应该让目标函数输出负RMSE，这样最大化负RMSE后，才是最小化真正的RMSE。）当我们定义的目标函数是准确率，或者auc等指标，则可以让目标函数的输出保持原样。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2926e677-d1fa-4417-ab00-cbf28c36295e",
      "metadata": {
        "id": "2926e677-d1fa-4417-ab00-cbf28c36295e"
      },
      "outputs": [],
      "source": [
        "def bayesopt_objective(n_estimators,max_depth,max_features,min_impurity_decrease):\n",
        "    \n",
        "    #定义评估器\n",
        "    #需要调整的超参数等于目标函数的输入，不需要调整的超参数则直接等于固定值\n",
        "    #默认参数输入一定是浮点数，因此需要套上int函数处理成整数\n",
        "    reg = RFR(n_estimators = int(n_estimators)\n",
        "              ,max_depth = int(max_depth)\n",
        "              ,max_features = int(max_features)\n",
        "              ,min_impurity_decrease = min_impurity_decrease\n",
        "              ,random_state=1412\n",
        "              ,verbose=False #可自行决定是否开启森林建树的verbose\n",
        "              ,n_jobs=-1)\n",
        "    \n",
        "    #定义损失的输出，5折交叉验证下的结果，输出负根均方误差（-RMSE）\n",
        "    #注意，交叉验证需要使用数据，但我们不能让数据X,y成为目标函数的输入\n",
        "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
        "    validation_loss = cross_validate(reg,X,y\n",
        "                                     ,scoring=\"neg_root_mean_squared_error\"\n",
        "                                     ,cv=cv\n",
        "                                     ,verbose=False\n",
        "                                     ,n_jobs=-1\n",
        "                                     ,error_score='raise'\n",
        "                                     #如果交叉验证中的算法执行报错，则告诉我们错误的理由\n",
        "                                    )\n",
        "    \n",
        "    #交叉验证输出的评估指标是负根均方误差，因此本来就是负的损失\n",
        "    #目标函数可直接输出该损失的均值\n",
        "    return np.mean(validation_loss[\"test_score\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "771562fa-1ba6-4eef-acbc-4108103346f4",
      "metadata": {
        "id": "771562fa-1ba6-4eef-acbc-4108103346f4"
      },
      "source": [
        "- 2 定义参数空间"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "898407d2-b610-40ac-80c2-abeff04f1268",
      "metadata": {
        "id": "898407d2-b610-40ac-80c2-abeff04f1268"
      },
      "source": [
        "在任意超参数优化器中，优化器会将参数空格中的超参数组合作为备选组合，一组一组输入到算法中进行训练。在贝叶斯优化中，超参数组合会被输入我们定义好的目标函数$f(x)$中。\n",
        "\n",
        "在bayes_opt中，我们使用字典方式来定义参数空间，其中参数的名称为键，参数的取值范围为值。且任意参数的取值范围为双向闭区间，以下方的空间为例，在n_estimators的取值中，80与100都可以被取到。\n",
        "\n",
        "以下参数空间与我们在随机森林中获得最高分的随机搜索的范围高度相似。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c525e5e-b837-4a34-8af1-f49352acb0f5",
      "metadata": {
        "id": "7c525e5e-b837-4a34-8af1-f49352acb0f5"
      },
      "outputs": [],
      "source": [
        "param_grid_simple = {'n_estimators': (80,100)\n",
        "                     , 'max_depth':(10,25)\n",
        "                     , \"max_features\": (10,20)\n",
        "                     , \"min_impurity_decrease\":(0,1)\n",
        "                    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a1f16e-f464-4689-a0d7-a2db1f9ca564",
      "metadata": {
        "id": "45a1f16e-f464-4689-a0d7-a2db1f9ca564"
      },
      "source": [
        "需要注意的是，bayes_opt只支持填写参数空间的上界与下界，不支持填写步长等参数，且bayes_opt会将所有参数都当作连续型超参进行处理，**因此bayes_opt会直接取出闭区间中任意浮点数作为备选参数**。例如，取92.28作为n_estimators的值。\n",
        "\n",
        "这也是为什么在目标函数中，我们需要对整数型超参的取值都套上int函数。假设优化器取出92.28作为n_estimators的值，实际传入随机森林算法的会是int(92.28) = 92，如此我们可以保证算法运行过程中不会因参数类型不符而报错。也因为bayes_opt的这个性质，**输入bayes_opt的参数空间天生会比其他贝叶斯优化库更大/更密，因此需要的迭代次数也更多**。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74096c22-430b-4a08-9409-66cdc0f45e8e",
      "metadata": {
        "id": "74096c22-430b-4a08-9409-66cdc0f45e8e"
      },
      "source": [
        "- 3 定义优化目标函数的具体流程\n",
        "\n",
        "在有了目标函数与参数空间之后，我们就可以按bayes_opt的规则进行优化了。在任意贝叶斯优化算法的实践过程中，一定都有涉及到随机性的过程——例如，随机抽取点作为观测点，随机抽样部分观测点进行采集函数的计算等等。**在大部分优化库当中，这种随机性是无法控制的**，即便允许我们填写随机数种子，优化算法也不能固定下来。因此我们可以尝试填写随机数种子，但需要记住优化算法每次运行时一定都会不一样。\n",
        "\n",
        "虽然，优化算法无法被复现，但是优化算法得出的最佳超参数的结果却是可以被复现的。只要优化完毕之后，可以从优化算法的实例化对象中取出最佳参数组合以及最佳分数，该最佳参数组合被输入到交叉验证中后，是一定可以复现其最佳分数的。如果没能复现最佳分数，则是交叉验证过程的随机数种子设置存在问题，或者优化算法的迭代流程存在问题。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e7e78e1-2641-40b1-b0c7-9a536fc6f4bb",
      "metadata": {
        "id": "8e7e78e1-2641-40b1-b0c7-9a536fc6f4bb"
      },
      "outputs": [],
      "source": [
        "def param_bayes_opt(init_points,n_iter):\n",
        "    \n",
        "    #定义优化器，先实例化优化器\n",
        "    opt = BayesianOptimization(bayesopt_objective #需要优化的目标函数\n",
        "                               ,param_grid_simple #备选参数空间\n",
        "                               ,random_state=1412 #随机数种子，虽然无法控制住\n",
        "                              )\n",
        "    \n",
        "    #使用优化器，记住bayes_opt只支持最大化\n",
        "    opt.maximize(init_points = init_points #抽取多少个初始观测值\n",
        "                 , n_iter=n_iter #一共观测/迭代多少次\n",
        "                )\n",
        "    \n",
        "    #优化完成，取出最佳参数与最佳分数\n",
        "    params_best = opt.max[\"params\"]\n",
        "    score_best = opt.max[\"target\"]\n",
        "    \n",
        "    #打印最佳参数与最佳分数\n",
        "    print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
        "          \"\\n\",\"\\n\",\"best cvscore: \", score_best)\n",
        "    \n",
        "    #返回最佳参数与最佳分数\n",
        "    return params_best, score_best"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef876d8f-94f3-4c45-a646-a9822f208bab",
      "metadata": {
        "id": "ef876d8f-94f3-4c45-a646-a9822f208bab"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13583326-fa62-497c-a5fb-96293d7861ac",
      "metadata": {
        "id": "13583326-fa62-497c-a5fb-96293d7861ac"
      },
      "source": [
        "- 4 定义验证函数（非必须）"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d20d780-e791-413f-850d-47b7ddda5265",
      "metadata": {
        "id": "2d20d780-e791-413f-850d-47b7ddda5265"
      },
      "source": [
        "优化后的结果是可以复现的，即我们可以对优化算法给出的最优参数进行再验证，其中验证函数与目标函数高度相似，输入参数或超参数空间、输出最终的损失函数结果。在使用sklearn中自带的优化算法时，由于优化算法自己会执行分割数据、交叉验证的步骤，因此优化算法得出的最优分数往往与我们自身验证的分数不同（因为交叉验证时的数据分割不同）。然而在贝叶斯优化过程中，目标函数中的交叉验证即数据分割都是我们自己规定的，**因此原则上来说，只要在目标函数中设置了随机数种子，贝叶斯优化给出的最佳分数一定与我们验证后的分数相同**，所以当你对优化过程的代码比较熟悉时，可以不用进行二次验证。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c313efce-64d0-4929-a888-550f2d47d1c3",
      "metadata": {
        "id": "c313efce-64d0-4929-a888-550f2d47d1c3"
      },
      "outputs": [],
      "source": [
        "def bayes_opt_validation(params_best):\n",
        "    \n",
        "    reg = RFR(n_estimators = int(params_best[\"n_estimators\"]) \n",
        "              ,max_depth = int(params_best[\"max_depth\"])\n",
        "              ,max_features = int(params_best[\"max_features\"])\n",
        "              ,min_impurity_decrease = params_best[\"min_impurity_decrease\"]\n",
        "              ,random_state=1412\n",
        "              ,verbose=False\n",
        "              ,n_jobs=-1)\n",
        "\n",
        "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
        "    validation_loss = cross_validate(reg,X,y\n",
        "                                     ,scoring=\"neg_root_mean_squared_error\"\n",
        "                                     ,cv=cv\n",
        "                                     ,verbose=False\n",
        "                                     ,n_jobs=-1\n",
        "                                    )\n",
        "    return np.mean(validation_loss[\"test_score\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20f98965-969f-4a05-8965-b5e3592d542b",
      "metadata": {
        "id": "20f98965-969f-4a05-8965-b5e3592d542b"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d656828-b589-4328-8a7f-870e6d1644d5",
      "metadata": {
        "id": "5d656828-b589-4328-8a7f-870e6d1644d5"
      },
      "source": [
        "- 5 执行实际优化流程"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b29c7160-8ab2-4f5d-9b7a-5c56a79ae03f",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "b29c7160-8ab2-4f5d-9b7a-5c56a79ae03f",
        "outputId": "44649902-b79c-4159-a4dd-141719313473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | max_depth | max_fe... | min_im... | n_esti... |\n",
            "-------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.948e+0\u001b[0m | \u001b[0m 23.2    \u001b[0m | \u001b[0m 17.52   \u001b[0m | \u001b[0m 0.06379 \u001b[0m | \u001b[0m 88.79   \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.909e+0\u001b[0m | \u001b[95m 14.8    \u001b[0m | \u001b[95m 17.61   \u001b[0m | \u001b[95m 0.9214  \u001b[0m | \u001b[95m 97.58   \u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m-2.9e+04 \u001b[0m | \u001b[95m 15.86   \u001b[0m | \u001b[95m 15.56   \u001b[0m | \u001b[95m 0.2661  \u001b[0m | \u001b[95m 87.98   \u001b[0m |\n",
            "| \u001b[95m 4       \u001b[0m | \u001b[95m-2.887e+0\u001b[0m | \u001b[95m 14.05   \u001b[0m | \u001b[95m 16.84   \u001b[0m | \u001b[95m 0.06744 \u001b[0m | \u001b[95m 89.72   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 18.71   \u001b[0m | \u001b[0m 19.17   \u001b[0m | \u001b[0m 0.9315  \u001b[0m | \u001b[0m 83.7    \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.895e+0\u001b[0m | \u001b[0m 17.7    \u001b[0m | \u001b[0m 19.58   \u001b[0m | \u001b[0m 0.7127  \u001b[0m | \u001b[0m 89.18   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.968e+0\u001b[0m | \u001b[0m 14.21   \u001b[0m | \u001b[0m 12.62   \u001b[0m | \u001b[0m 0.3381  \u001b[0m | \u001b[0m 91.51   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-2.91e+04\u001b[0m | \u001b[0m 23.23   \u001b[0m | \u001b[0m 10.89   \u001b[0m | \u001b[0m 0.6078  \u001b[0m | \u001b[0m 95.06   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.891e+0\u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 14.0    \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 80.16   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.958e+0\u001b[0m | \u001b[0m 11.52   \u001b[0m | \u001b[0m 12.58   \u001b[0m | \u001b[0m 0.03276 \u001b[0m | \u001b[0m 92.56   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m-2.91e+04\u001b[0m | \u001b[0m 13.14   \u001b[0m | \u001b[0m 13.31   \u001b[0m | \u001b[0m 0.2563  \u001b[0m | \u001b[0m 98.24   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m-2.95e+04\u001b[0m | \u001b[0m 17.94   \u001b[0m | \u001b[0m 11.48   \u001b[0m | \u001b[0m 0.3778  \u001b[0m | \u001b[0m 82.09   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m-2.913e+0\u001b[0m | \u001b[0m 16.02   \u001b[0m | \u001b[0m 17.03   \u001b[0m | \u001b[0m 0.7735  \u001b[0m | \u001b[0m 88.31   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m-2.925e+0\u001b[0m | \u001b[0m 13.92   \u001b[0m | \u001b[0m 15.04   \u001b[0m | \u001b[0m 0.529   \u001b[0m | \u001b[0m 93.66   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m-2.938e+0\u001b[0m | \u001b[0m 12.51   \u001b[0m | \u001b[0m 13.69   \u001b[0m | \u001b[0m 0.4482  \u001b[0m | \u001b[0m 99.9    \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m-2.933e+0\u001b[0m | \u001b[0m 17.73   \u001b[0m | \u001b[0m 10.05   \u001b[0m | \u001b[0m 0.4143  \u001b[0m | \u001b[0m 82.79   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m-2.952e+0\u001b[0m | \u001b[0m 16.6    \u001b[0m | \u001b[0m 10.84   \u001b[0m | \u001b[0m 0.9134  \u001b[0m | \u001b[0m 88.37   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m-2.958e+0\u001b[0m | \u001b[0m 21.92   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 85.86   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m-2.934e+0\u001b[0m | \u001b[0m 14.07   \u001b[0m | \u001b[0m 11.38   \u001b[0m | \u001b[0m 0.05068 \u001b[0m | \u001b[0m 91.53   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m-2.962e+0\u001b[0m | \u001b[0m 10.35   \u001b[0m | \u001b[0m 17.38   \u001b[0m | \u001b[0m 0.7624  \u001b[0m | \u001b[0m 99.19   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m-2.937e+0\u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 16.09   \u001b[0m | \u001b[0m 0.3349  \u001b[0m | \u001b[0m 88.16   \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 14.95   \u001b[0m | \u001b[0m 16.89   \u001b[0m | \u001b[0m 0.07827 \u001b[0m | \u001b[0m 89.8    \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m-2.908e+0\u001b[0m | \u001b[0m 14.21   \u001b[0m | \u001b[0m 17.99   \u001b[0m | \u001b[0m 0.4688  \u001b[0m | \u001b[0m 90.52   \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 18.29   \u001b[0m | \u001b[0m 19.35   \u001b[0m | \u001b[0m 0.8535  \u001b[0m | \u001b[0m 85.12   \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m-2.968e+0\u001b[0m | \u001b[0m 19.49   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 84.53   \u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m-2.906e+0\u001b[0m | \u001b[0m 17.9    \u001b[0m | \u001b[0m 18.8    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 84.29   \u001b[0m |\n",
            "| \u001b[95m 27      \u001b[0m | \u001b[95m-2.886e+0\u001b[0m | \u001b[95m 14.42   \u001b[0m | \u001b[95m 16.55   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 90.57   \u001b[0m |\n",
            "| \u001b[95m 28      \u001b[0m | \u001b[95m-2.885e+0\u001b[0m | \u001b[95m 14.52   \u001b[0m | \u001b[95m 16.53   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 90.12   \u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m-2.902e+0\u001b[0m | \u001b[0m 15.17   \u001b[0m | \u001b[0m 15.66   \u001b[0m | \u001b[0m 0.319   \u001b[0m | \u001b[0m 89.94   \u001b[0m |\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m-2.928e+0\u001b[0m | \u001b[0m 13.27   \u001b[0m | \u001b[0m 16.41   \u001b[0m | \u001b[0m 0.8249  \u001b[0m | \u001b[0m 90.6    \u001b[0m |\n",
            "| \u001b[95m 31      \u001b[0m | \u001b[95m-2.881e+0\u001b[0m | \u001b[95m 15.2    \u001b[0m | \u001b[95m 16.7    \u001b[0m | \u001b[95m 0.6155  \u001b[0m | \u001b[95m 90.9    \u001b[0m |\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m-2.905e+0\u001b[0m | \u001b[0m 16.04   \u001b[0m | \u001b[0m 17.33   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 90.32   \u001b[0m |\n",
            "| \u001b[0m 33      \u001b[0m | \u001b[0m-2.889e+0\u001b[0m | \u001b[0m 18.73   \u001b[0m | \u001b[0m 18.79   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 82.43   \u001b[0m |\n",
            "| \u001b[0m 34      \u001b[0m | \u001b[0m-2.891e+0\u001b[0m | \u001b[0m 17.79   \u001b[0m | \u001b[0m 19.32   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 86.55   \u001b[0m |\n",
            "| \u001b[95m 35      \u001b[0m | \u001b[95m-2.876e+0\u001b[0m | \u001b[95m 19.43   \u001b[0m | \u001b[95m 17.86   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 83.36   \u001b[0m |\n",
            "| \u001b[0m 36      \u001b[0m | \u001b[0m-2.905e+0\u001b[0m | \u001b[0m 20.3    \u001b[0m | \u001b[0m 17.85   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 82.25   \u001b[0m |\n",
            "| \u001b[0m 37      \u001b[0m | \u001b[0m-2.899e+0\u001b[0m | \u001b[0m 18.43   \u001b[0m | \u001b[0m 16.97   \u001b[0m | \u001b[0m 0.6339  \u001b[0m | \u001b[0m 82.39   \u001b[0m |\n",
            "| \u001b[0m 38      \u001b[0m | \u001b[0m-2.929e+0\u001b[0m | \u001b[0m 18.72   \u001b[0m | \u001b[0m 17.58   \u001b[0m | \u001b[0m 0.8506  \u001b[0m | \u001b[0m 86.01   \u001b[0m |\n",
            "| \u001b[0m 39      \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 16.64   \u001b[0m | \u001b[0m 19.95   \u001b[0m | \u001b[0m 0.8027  \u001b[0m | \u001b[0m 85.54   \u001b[0m |\n",
            "| \u001b[0m 40      \u001b[0m | \u001b[0m-2.889e+0\u001b[0m | \u001b[0m 16.01   \u001b[0m | \u001b[0m 19.89   \u001b[0m | \u001b[0m 0.9527  \u001b[0m | \u001b[0m 87.31   \u001b[0m |\n",
            "| \u001b[0m 41      \u001b[0m | \u001b[0m-2.89e+04\u001b[0m | \u001b[0m 15.33   \u001b[0m | \u001b[0m 15.78   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 80.25   \u001b[0m |\n",
            "| \u001b[0m 42      \u001b[0m | \u001b[0m-2.939e+0\u001b[0m | \u001b[0m 13.54   \u001b[0m | \u001b[0m 15.32   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 80.0    \u001b[0m |\n",
            "| \u001b[0m 43      \u001b[0m | \u001b[0m-2.947e+0\u001b[0m | \u001b[0m 16.93   \u001b[0m | \u001b[0m 14.72   \u001b[0m | \u001b[0m 0.81    \u001b[0m | \u001b[0m 80.6    \u001b[0m |\n",
            "| \u001b[0m 44      \u001b[0m | \u001b[0m-2.895e+0\u001b[0m | \u001b[0m 17.53   \u001b[0m | \u001b[0m 19.89   \u001b[0m | \u001b[0m 0.3215  \u001b[0m | \u001b[0m 87.48   \u001b[0m |\n",
            "| \u001b[0m 45      \u001b[0m | \u001b[0m-2.889e+0\u001b[0m | \u001b[0m 18.71   \u001b[0m | \u001b[0m 18.17   \u001b[0m | \u001b[0m 0.03282 \u001b[0m | \u001b[0m 82.97   \u001b[0m |\n",
            "| \u001b[0m 46      \u001b[0m | \u001b[0m-2.903e+0\u001b[0m | \u001b[0m 15.93   \u001b[0m | \u001b[0m 19.28   \u001b[0m | \u001b[0m 0.007221\u001b[0m | \u001b[0m 86.27   \u001b[0m |\n",
            "| \u001b[0m 47      \u001b[0m | \u001b[0m-2.9e+04 \u001b[0m | \u001b[0m 16.01   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 88.86   \u001b[0m |\n",
            "| \u001b[95m 48      \u001b[0m | \u001b[95m-2.875e+0\u001b[0m | \u001b[95m 15.67   \u001b[0m | \u001b[95m 17.5    \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 80.3    \u001b[0m |\n",
            "| \u001b[0m 49      \u001b[0m | \u001b[0m-2.878e+0\u001b[0m | \u001b[0m 15.38   \u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 81.6    \u001b[0m |\n",
            "| \u001b[95m 50      \u001b[0m | \u001b[95m-2.853e+0\u001b[0m | \u001b[95m 15.99   \u001b[0m | \u001b[95m 18.21   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 81.1    \u001b[0m |\n",
            "| \u001b[0m 51      \u001b[0m | \u001b[0m-2.904e+0\u001b[0m | \u001b[0m 15.55   \u001b[0m | \u001b[0m 19.09   \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 81.11   \u001b[0m |\n",
            "| \u001b[0m 52      \u001b[0m | \u001b[0m-2.924e+0\u001b[0m | \u001b[0m 16.73   \u001b[0m | \u001b[0m 17.63   \u001b[0m | \u001b[0m 0.4579  \u001b[0m | \u001b[0m 81.92   \u001b[0m |\n",
            "| \u001b[0m 53      \u001b[0m | \u001b[0m-2.876e+0\u001b[0m | \u001b[0m 15.32   \u001b[0m | \u001b[0m 17.65   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 80.81   \u001b[0m |\n",
            "| \u001b[0m 54      \u001b[0m | \u001b[0m-2.925e+0\u001b[0m | \u001b[0m 16.63   \u001b[0m | \u001b[0m 18.02   \u001b[0m | \u001b[0m 0.5035  \u001b[0m | \u001b[0m 80.17   \u001b[0m |\n",
            "| \u001b[95m 55      \u001b[0m | \u001b[95m-2.852e+0\u001b[0m | \u001b[95m 15.45   \u001b[0m | \u001b[95m 18.28   \u001b[0m | \u001b[95m 0.09286 \u001b[0m | \u001b[95m 81.23   \u001b[0m |\n",
            "| \u001b[0m 56      \u001b[0m | \u001b[0m-2.853e+0\u001b[0m | \u001b[0m 15.55   \u001b[0m | \u001b[0m 18.11   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 81.88   \u001b[0m |\n",
            "| \u001b[0m 57      \u001b[0m | \u001b[0m-2.907e+0\u001b[0m | \u001b[0m 14.55   \u001b[0m | \u001b[0m 18.07   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 82.08   \u001b[0m |\n",
            "| \u001b[0m 58      \u001b[0m | \u001b[0m-2.921e+0\u001b[0m | \u001b[0m 16.2    \u001b[0m | \u001b[0m 18.99   \u001b[0m | \u001b[0m 0.0997  \u001b[0m | \u001b[0m 81.97   \u001b[0m |\n",
            "| \u001b[95m 59      \u001b[0m | \u001b[95m-2.852e+0\u001b[0m | \u001b[95m 15.6    \u001b[0m | \u001b[95m 18.06   \u001b[0m | \u001b[95m 0.5865  \u001b[0m | \u001b[95m 81.86   \u001b[0m |\n",
            "| \u001b[0m 60      \u001b[0m | \u001b[0m-2.876e+0\u001b[0m | \u001b[0m 15.49   \u001b[0m | \u001b[0m 17.44   \u001b[0m | \u001b[0m 0.07222 \u001b[0m | \u001b[0m 81.46   \u001b[0m |\n",
            "| \u001b[0m 61      \u001b[0m | \u001b[0m-2.877e+0\u001b[0m | \u001b[0m 15.42   \u001b[0m | \u001b[0m 17.81   \u001b[0m | \u001b[0m 0.9484  \u001b[0m | \u001b[0m 82.82   \u001b[0m |\n",
            "| \u001b[0m 62      \u001b[0m | \u001b[0m-2.853e+0\u001b[0m | \u001b[0m 15.55   \u001b[0m | \u001b[0m 18.09   \u001b[0m | \u001b[0m 0.5876  \u001b[0m | \u001b[0m 80.75   \u001b[0m |\n",
            "| \u001b[0m 63      \u001b[0m | \u001b[0m-2.923e+0\u001b[0m | \u001b[0m 19.64   \u001b[0m | \u001b[0m 16.39   \u001b[0m | \u001b[0m 0.7572  \u001b[0m | \u001b[0m 83.73   \u001b[0m |\n",
            "| \u001b[0m 64      \u001b[0m | \u001b[0m-2.909e+0\u001b[0m | \u001b[0m 14.75   \u001b[0m | \u001b[0m 17.82   \u001b[0m | \u001b[0m 0.9799  \u001b[0m | \u001b[0m 81.05   \u001b[0m |\n",
            "| \u001b[0m 65      \u001b[0m | \u001b[0m-2.88e+04\u001b[0m | \u001b[0m 15.32   \u001b[0m | \u001b[0m 16.56   \u001b[0m | \u001b[0m 0.5475  \u001b[0m | \u001b[0m 83.21   \u001b[0m |\n",
            "| \u001b[0m 66      \u001b[0m | \u001b[0m-2.914e+0\u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 17.24   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 84.24   \u001b[0m |\n",
            "| \u001b[0m 67      \u001b[0m | \u001b[0m-2.896e+0\u001b[0m | \u001b[0m 15.05   \u001b[0m | \u001b[0m 15.7    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 82.43   \u001b[0m |\n",
            "| \u001b[0m 68      \u001b[0m | \u001b[0m-2.895e+0\u001b[0m | \u001b[0m 15.77   \u001b[0m | \u001b[0m 15.46   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 83.74   \u001b[0m |\n",
            "| \u001b[0m 69      \u001b[0m | \u001b[0m-2.853e+0\u001b[0m | \u001b[0m 15.26   \u001b[0m | \u001b[0m 18.45   \u001b[0m | \u001b[0m 0.02002 \u001b[0m | \u001b[0m 80.46   \u001b[0m |\n",
            "| \u001b[0m 70      \u001b[0m | \u001b[0m-2.941e+0\u001b[0m | \u001b[0m 16.16   \u001b[0m | \u001b[0m 16.76   \u001b[0m | \u001b[0m 0.2009  \u001b[0m | \u001b[0m 92.03   \u001b[0m |\n",
            "| \u001b[0m 71      \u001b[0m | \u001b[0m-2.909e+0\u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 19.08   \u001b[0m | \u001b[0m 0.0958  \u001b[0m | \u001b[0m 80.04   \u001b[0m |\n",
            "| \u001b[0m 72      \u001b[0m | \u001b[0m-2.875e+0\u001b[0m | \u001b[0m 15.59   \u001b[0m | \u001b[0m 17.78   \u001b[0m | \u001b[0m 0.0424  \u001b[0m | \u001b[0m 82.72   \u001b[0m |\n",
            "| \u001b[0m 73      \u001b[0m | \u001b[0m-2.967e+0\u001b[0m | \u001b[0m 14.36   \u001b[0m | \u001b[0m 12.3    \u001b[0m | \u001b[0m 0.6712  \u001b[0m | \u001b[0m 80.33   \u001b[0m |\n",
            "| \u001b[0m 74      \u001b[0m | \u001b[0m-2.907e+0\u001b[0m | \u001b[0m 14.23   \u001b[0m | \u001b[0m 19.86   \u001b[0m | \u001b[0m 0.9782  \u001b[0m | \u001b[0m 86.91   \u001b[0m |\n",
            "| \u001b[0m 75      \u001b[0m | \u001b[0m-2.972e+0\u001b[0m | \u001b[0m 19.33   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 88.35   \u001b[0m |\n",
            "| \u001b[0m 76      \u001b[0m | \u001b[0m-2.894e+0\u001b[0m | \u001b[0m 17.28   \u001b[0m | \u001b[0m 19.91   \u001b[0m | \u001b[0m 0.6293  \u001b[0m | \u001b[0m 90.76   \u001b[0m |\n",
            "| \u001b[0m 77      \u001b[0m | \u001b[0m-2.935e+0\u001b[0m | \u001b[0m 13.92   \u001b[0m | \u001b[0m 15.84   \u001b[0m | \u001b[0m 0.1577  \u001b[0m | \u001b[0m 83.59   \u001b[0m |\n",
            "| \u001b[0m 78      \u001b[0m | \u001b[0m-2.883e+0\u001b[0m | \u001b[0m 18.14   \u001b[0m | \u001b[0m 19.61   \u001b[0m | \u001b[0m 0.6678  \u001b[0m | \u001b[0m 92.57   \u001b[0m |\n",
            "| \u001b[0m 79      \u001b[0m | \u001b[0m-2.93e+04\u001b[0m | \u001b[0m 19.34   \u001b[0m | \u001b[0m 18.94   \u001b[0m | \u001b[0m 0.5768  \u001b[0m | \u001b[0m 92.74   \u001b[0m |\n",
            "| \u001b[0m 80      \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 16.88   \u001b[0m | \u001b[0m 19.67   \u001b[0m | \u001b[0m 0.3616  \u001b[0m | \u001b[0m 93.24   \u001b[0m |\n",
            "| \u001b[0m 81      \u001b[0m | \u001b[0m-2.889e+0\u001b[0m | \u001b[0m 16.73   \u001b[0m | \u001b[0m 19.17   \u001b[0m | \u001b[0m 0.8361  \u001b[0m | \u001b[0m 91.97   \u001b[0m |\n",
            "| \u001b[0m 82      \u001b[0m | \u001b[0m-2.9e+04 \u001b[0m | \u001b[0m 17.85   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 93.95   \u001b[0m |\n",
            "| \u001b[0m 83      \u001b[0m | \u001b[0m-2.881e+0\u001b[0m | \u001b[0m 15.84   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 92.1    \u001b[0m |\n",
            "| \u001b[0m 84      \u001b[0m | \u001b[0m-2.9e+04 \u001b[0m | \u001b[0m 15.28   \u001b[0m | \u001b[0m 19.27   \u001b[0m | \u001b[0m 0.85    \u001b[0m | \u001b[0m 93.07   \u001b[0m |\n",
            "| \u001b[0m 85      \u001b[0m | \u001b[0m-2.902e+0\u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 19.74   \u001b[0m | \u001b[0m 0.3355  \u001b[0m | \u001b[0m 90.84   \u001b[0m |\n",
            "| \u001b[0m 86      \u001b[0m | \u001b[0m-2.901e+0\u001b[0m | \u001b[0m 15.86   \u001b[0m | \u001b[0m 19.64   \u001b[0m | \u001b[0m 0.252   \u001b[0m | \u001b[0m 95.07   \u001b[0m |\n",
            "| \u001b[0m 87      \u001b[0m | \u001b[0m-2.942e+0\u001b[0m | \u001b[0m 16.98   \u001b[0m | \u001b[0m 14.7    \u001b[0m | \u001b[0m 0.2749  \u001b[0m | \u001b[0m 86.28   \u001b[0m |\n",
            "| \u001b[0m 88      \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 13.06   \u001b[0m | \u001b[0m 19.95   \u001b[0m | \u001b[0m 0.6557  \u001b[0m | \u001b[0m 94.74   \u001b[0m |\n",
            "| \u001b[0m 89      \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 13.48   \u001b[0m | \u001b[0m 19.61   \u001b[0m | \u001b[0m 0.1196  \u001b[0m | \u001b[0m 96.02   \u001b[0m |\n",
            "| \u001b[0m 90      \u001b[0m | \u001b[0m-2.881e+0\u001b[0m | \u001b[0m 12.42   \u001b[0m | \u001b[0m 18.66   \u001b[0m | \u001b[0m 0.7506  \u001b[0m | \u001b[0m 95.3    \u001b[0m |\n",
            "| \u001b[0m 91      \u001b[0m | \u001b[0m-2.918e+0\u001b[0m | \u001b[0m 11.9    \u001b[0m | \u001b[0m 19.72   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 95.61   \u001b[0m |\n",
            "| \u001b[0m 92      \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 13.73   \u001b[0m | \u001b[0m 18.69   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 95.17   \u001b[0m |\n",
            "| \u001b[0m 93      \u001b[0m | \u001b[0m-2.877e+0\u001b[0m | \u001b[0m 12.65   \u001b[0m | \u001b[0m 18.6    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 93.96   \u001b[0m |\n",
            "| \u001b[0m 94      \u001b[0m | \u001b[0m-2.925e+0\u001b[0m | \u001b[0m 12.07   \u001b[0m | \u001b[0m 17.6    \u001b[0m | \u001b[0m 0.9865  \u001b[0m | \u001b[0m 94.43   \u001b[0m |\n",
            "| \u001b[0m 95      \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 13.28   \u001b[0m | \u001b[0m 18.87   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 94.21   \u001b[0m |\n",
            "| \u001b[0m 96      \u001b[0m | \u001b[0m-2.877e+0\u001b[0m | \u001b[0m 12.86   \u001b[0m | \u001b[0m 19.29   \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 92.65   \u001b[0m |\n",
            "| \u001b[0m 97      \u001b[0m | \u001b[0m-2.875e+0\u001b[0m | \u001b[0m 12.29   \u001b[0m | \u001b[0m 19.9    \u001b[0m | \u001b[0m 0.7932  \u001b[0m | \u001b[0m 93.42   \u001b[0m |\n",
            "| \u001b[0m 98      \u001b[0m | \u001b[0m-2.924e+0\u001b[0m | \u001b[0m 11.49   \u001b[0m | \u001b[0m 18.92   \u001b[0m | \u001b[0m 0.9259  \u001b[0m | \u001b[0m 92.54   \u001b[0m |\n",
            "| \u001b[0m 99      \u001b[0m | \u001b[0m-2.906e+0\u001b[0m | \u001b[0m 14.06   \u001b[0m | \u001b[0m 19.77   \u001b[0m | \u001b[0m 0.3828  \u001b[0m | \u001b[0m 92.67   \u001b[0m |\n",
            "| \u001b[0m 100     \u001b[0m | \u001b[0m-2.89e+04\u001b[0m | \u001b[0m 13.04   \u001b[0m | \u001b[0m 18.51   \u001b[0m | \u001b[0m 0.6317  \u001b[0m | \u001b[0m 96.31   \u001b[0m |\n",
            "| \u001b[0m 101     \u001b[0m | \u001b[0m-2.853e+0\u001b[0m | \u001b[0m 15.36   \u001b[0m | \u001b[0m 18.1    \u001b[0m | \u001b[0m 0.4371  \u001b[0m | \u001b[0m 80.01   \u001b[0m |\n",
            "| \u001b[0m 102     \u001b[0m | \u001b[0m-2.898e+0\u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 19.93   \u001b[0m | \u001b[0m 0.9062  \u001b[0m | \u001b[0m 96.9    \u001b[0m |\n",
            "| \u001b[0m 103     \u001b[0m | \u001b[0m-2.889e+0\u001b[0m | \u001b[0m 13.66   \u001b[0m | \u001b[0m 19.58   \u001b[0m | \u001b[0m 0.4008  \u001b[0m | \u001b[0m 98.42   \u001b[0m |\n",
            "| \u001b[0m 104     \u001b[0m | \u001b[0m-2.89e+04\u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 19.69   \u001b[0m | \u001b[0m 0.04412 \u001b[0m | \u001b[0m 91.96   \u001b[0m |\n",
            "| \u001b[0m 105     \u001b[0m | \u001b[0m-2.853e+0\u001b[0m | \u001b[0m 15.69   \u001b[0m | \u001b[0m 18.36   \u001b[0m | \u001b[0m 0.01086 \u001b[0m | \u001b[0m 80.16   \u001b[0m |\n",
            "| \u001b[0m 106     \u001b[0m | \u001b[0m-2.9e+04 \u001b[0m | \u001b[0m 14.83   \u001b[0m | \u001b[0m 19.7    \u001b[0m | \u001b[0m 0.4319  \u001b[0m | \u001b[0m 99.75   \u001b[0m |\n",
            "| \u001b[0m 107     \u001b[0m | \u001b[0m-2.884e+0\u001b[0m | \u001b[0m 18.21   \u001b[0m | \u001b[0m 19.92   \u001b[0m | \u001b[0m 0.1281  \u001b[0m | \u001b[0m 99.46   \u001b[0m |\n",
            "| \u001b[0m 108     \u001b[0m | \u001b[0m-2.95e+04\u001b[0m | \u001b[0m 19.8    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
            "| \u001b[0m 109     \u001b[0m | \u001b[0m-2.908e+0\u001b[0m | \u001b[0m 17.01   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.08407 \u001b[0m | \u001b[0m 98.65   \u001b[0m |\n",
            "| \u001b[0m 110     \u001b[0m | \u001b[0m-2.905e+0\u001b[0m | \u001b[0m 17.93   \u001b[0m | \u001b[0m 18.06   \u001b[0m | \u001b[0m 0.6703  \u001b[0m | \u001b[0m 99.44   \u001b[0m |\n",
            "| \u001b[0m 111     \u001b[0m | \u001b[0m-2.941e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 80.0    \u001b[0m |\n",
            "| \u001b[0m 112     \u001b[0m | \u001b[0m-2.928e+0\u001b[0m | \u001b[0m 19.14   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
            "| \u001b[0m 113     \u001b[0m | \u001b[0m-2.883e+0\u001b[0m | \u001b[0m 13.7    \u001b[0m | \u001b[0m 18.17   \u001b[0m | \u001b[0m 0.9195  \u001b[0m | \u001b[0m 92.96   \u001b[0m |\n",
            "| \u001b[0m 114     \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 13.06   \u001b[0m | \u001b[0m 19.1    \u001b[0m | \u001b[0m 0.93    \u001b[0m | \u001b[0m 93.48   \u001b[0m |\n",
            "| \u001b[0m 115     \u001b[0m | \u001b[0m-2.878e+0\u001b[0m | \u001b[0m 12.84   \u001b[0m | \u001b[0m 19.99   \u001b[0m | \u001b[0m 0.4258  \u001b[0m | \u001b[0m 91.65   \u001b[0m |\n",
            "| \u001b[0m 116     \u001b[0m | \u001b[0m-2.889e+0\u001b[0m | \u001b[0m 12.35   \u001b[0m | \u001b[0m 19.96   \u001b[0m | \u001b[0m 0.3574  \u001b[0m | \u001b[0m 89.73   \u001b[0m |\n",
            "| \u001b[0m 117     \u001b[0m | \u001b[0m-2.916e+0\u001b[0m | \u001b[0m 10.71   \u001b[0m | \u001b[0m 19.94   \u001b[0m | \u001b[0m 0.0938  \u001b[0m | \u001b[0m 88.5    \u001b[0m |\n",
            "| \u001b[0m 118     \u001b[0m | \u001b[0m-2.869e+0\u001b[0m | \u001b[0m 12.28   \u001b[0m | \u001b[0m 19.98   \u001b[0m | \u001b[0m 0.3843  \u001b[0m | \u001b[0m 99.26   \u001b[0m |\n",
            "| \u001b[0m 119     \u001b[0m | \u001b[0m-2.869e+0\u001b[0m | \u001b[0m 12.74   \u001b[0m | \u001b[0m 19.85   \u001b[0m | \u001b[0m 0.007808\u001b[0m | \u001b[0m 99.91   \u001b[0m |\n",
            "| \u001b[0m 120     \u001b[0m | \u001b[0m-2.891e+0\u001b[0m | \u001b[0m 13.21   \u001b[0m | \u001b[0m 19.26   \u001b[0m | \u001b[0m 0.9999  \u001b[0m | \u001b[0m 99.94   \u001b[0m |\n",
            "| \u001b[0m 121     \u001b[0m | \u001b[0m-2.914e+0\u001b[0m | \u001b[0m 11.59   \u001b[0m | \u001b[0m 19.63   \u001b[0m | \u001b[0m 0.07302 \u001b[0m | \u001b[0m 99.93   \u001b[0m |\n",
            "| \u001b[0m 122     \u001b[0m | \u001b[0m-2.87e+04\u001b[0m | \u001b[0m 12.73   \u001b[0m | \u001b[0m 19.19   \u001b[0m | \u001b[0m 0.02993 \u001b[0m | \u001b[0m 98.63   \u001b[0m |\n",
            "| \u001b[0m 123     \u001b[0m | \u001b[0m-2.872e+0\u001b[0m | \u001b[0m 12.47   \u001b[0m | \u001b[0m 19.88   \u001b[0m | \u001b[0m 0.5012  \u001b[0m | \u001b[0m 97.91   \u001b[0m |\n",
            "| \u001b[0m 124     \u001b[0m | \u001b[0m-2.915e+0\u001b[0m | \u001b[0m 11.48   \u001b[0m | \u001b[0m 19.24   \u001b[0m | \u001b[0m 0.9974  \u001b[0m | \u001b[0m 97.93   \u001b[0m |\n",
            "| \u001b[0m 125     \u001b[0m | \u001b[0m-2.892e+0\u001b[0m | \u001b[0m 13.28   \u001b[0m | \u001b[0m 18.95   \u001b[0m | \u001b[0m 0.01142 \u001b[0m | \u001b[0m 99.52   \u001b[0m |\n",
            "| \u001b[0m 126     \u001b[0m | \u001b[0m-2.877e+0\u001b[0m | \u001b[0m 12.26   \u001b[0m | \u001b[0m 19.89   \u001b[0m | \u001b[0m 0.0868  \u001b[0m | \u001b[0m 92.72   \u001b[0m |\n",
            "| \u001b[0m 127     \u001b[0m | \u001b[0m-2.859e+0\u001b[0m | \u001b[0m 24.86   \u001b[0m | \u001b[0m 14.87   \u001b[0m | \u001b[0m 0.4054  \u001b[0m | \u001b[0m 99.26   \u001b[0m |\n",
            "| \u001b[0m 128     \u001b[0m | \u001b[0m-2.873e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 14.04   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 99.6    \u001b[0m |\n",
            "| \u001b[0m 129     \u001b[0m | \u001b[0m-2.929e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 15.45   \u001b[0m | \u001b[0m 0.9673  \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
            "| \u001b[0m 130     \u001b[0m | \u001b[0m-2.859e+0\u001b[0m | \u001b[0m 24.78   \u001b[0m | \u001b[0m 14.17   \u001b[0m | \u001b[0m 0.06212 \u001b[0m | \u001b[0m 98.69   \u001b[0m |\n",
            "| \u001b[0m 131     \u001b[0m | \u001b[0m-2.859e+0\u001b[0m | \u001b[0m 24.24   \u001b[0m | \u001b[0m 14.61   \u001b[0m | \u001b[0m 0.8034  \u001b[0m | \u001b[0m 98.56   \u001b[0m |\n",
            "| \u001b[0m 132     \u001b[0m | \u001b[0m-2.856e+0\u001b[0m | \u001b[0m 23.96   \u001b[0m | \u001b[0m 14.38   \u001b[0m | \u001b[0m 0.04263 \u001b[0m | \u001b[0m 99.34   \u001b[0m |\n",
            "| \u001b[0m 133     \u001b[0m | \u001b[0m-2.94e+04\u001b[0m | \u001b[0m 24.2    \u001b[0m | \u001b[0m 15.22   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 98.55   \u001b[0m |\n",
            "| \u001b[0m 134     \u001b[0m | \u001b[0m-2.923e+0\u001b[0m | \u001b[0m 24.12   \u001b[0m | \u001b[0m 13.81   \u001b[0m | \u001b[0m 0.6933  \u001b[0m | \u001b[0m 99.04   \u001b[0m |\n",
            "| \u001b[0m 135     \u001b[0m | \u001b[0m-2.858e+0\u001b[0m | \u001b[0m 24.97   \u001b[0m | \u001b[0m 14.6    \u001b[0m | \u001b[0m 0.8047  \u001b[0m | \u001b[0m 99.24   \u001b[0m |\n",
            "| \u001b[0m 136     \u001b[0m | \u001b[0m-2.858e+0\u001b[0m | \u001b[0m 24.78   \u001b[0m | \u001b[0m 14.14   \u001b[0m | \u001b[0m 0.1613  \u001b[0m | \u001b[0m 99.61   \u001b[0m |\n",
            "| \u001b[0m 137     \u001b[0m | \u001b[0m-2.859e+0\u001b[0m | \u001b[0m 24.91   \u001b[0m | \u001b[0m 14.74   \u001b[0m | \u001b[0m 0.8767  \u001b[0m | \u001b[0m 98.07   \u001b[0m |\n",
            "| \u001b[0m 138     \u001b[0m | \u001b[0m-2.856e+0\u001b[0m | \u001b[0m 23.63   \u001b[0m | \u001b[0m 14.27   \u001b[0m | \u001b[0m 0.1131  \u001b[0m | \u001b[0m 99.81   \u001b[0m |\n",
            "| \u001b[0m 139     \u001b[0m | \u001b[0m-2.917e+0\u001b[0m | \u001b[0m 24.85   \u001b[0m | \u001b[0m 13.76   \u001b[0m | \u001b[0m 0.8032  \u001b[0m | \u001b[0m 97.85   \u001b[0m |\n",
            "| \u001b[0m 140     \u001b[0m | \u001b[0m-2.859e+0\u001b[0m | \u001b[0m 24.31   \u001b[0m | \u001b[0m 14.65   \u001b[0m | \u001b[0m 0.3618  \u001b[0m | \u001b[0m 99.91   \u001b[0m |\n",
            "| \u001b[95m 141     \u001b[0m | \u001b[95m-2.845e+0\u001b[0m | \u001b[95m 22.75   \u001b[0m | \u001b[95m 14.43   \u001b[0m | \u001b[95m 0.3707  \u001b[0m | \u001b[95m 99.28   \u001b[0m |\n",
            "| \u001b[95m 142     \u001b[0m | \u001b[95m-2.845e+0\u001b[0m | \u001b[95m 22.77   \u001b[0m | \u001b[95m 14.8    \u001b[0m | \u001b[95m 0.02135 \u001b[0m | \u001b[95m 99.85   \u001b[0m |\n",
            "| \u001b[0m 143     \u001b[0m | \u001b[0m-2.845e+0\u001b[0m | \u001b[0m 22.42   \u001b[0m | \u001b[0m 14.24   \u001b[0m | \u001b[0m 0.198   \u001b[0m | \u001b[0m 99.91   \u001b[0m |\n",
            "| \u001b[0m 144     \u001b[0m | \u001b[0m-2.925e+0\u001b[0m | \u001b[0m 22.83   \u001b[0m | \u001b[0m 15.08   \u001b[0m | \u001b[0m 0.5595  \u001b[0m | \u001b[0m 99.81   \u001b[0m |\n",
            "| \u001b[95m 145     \u001b[0m | \u001b[95m-2.844e+0\u001b[0m | \u001b[95m 22.85   \u001b[0m | \u001b[95m 14.19   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 99.53   \u001b[0m |\n",
            "| \u001b[0m 146     \u001b[0m | \u001b[0m-2.844e+0\u001b[0m | \u001b[0m 22.23   \u001b[0m | \u001b[0m 14.53   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 99.35   \u001b[0m |\n",
            "| \u001b[0m 147     \u001b[0m | \u001b[0m-2.908e+0\u001b[0m | \u001b[0m 22.2    \u001b[0m | \u001b[0m 13.9    \u001b[0m | \u001b[0m 0.3868  \u001b[0m | \u001b[0m 99.11   \u001b[0m |\n",
            "| \u001b[0m 148     \u001b[0m | \u001b[0m-2.869e+0\u001b[0m | \u001b[0m 12.85   \u001b[0m | \u001b[0m 19.93   \u001b[0m | \u001b[0m 0.7621  \u001b[0m | \u001b[0m 99.26   \u001b[0m |\n",
            "| \u001b[0m 149     \u001b[0m | \u001b[0m-2.96e+04\u001b[0m | \u001b[0m 21.35   \u001b[0m | \u001b[0m 15.39   \u001b[0m | \u001b[0m 0.2309  \u001b[0m | \u001b[0m 99.81   \u001b[0m |\n",
            "| \u001b[0m 150     \u001b[0m | \u001b[0m-2.856e+0\u001b[0m | \u001b[0m 23.2    \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 0.0109  \u001b[0m | \u001b[0m 99.33   \u001b[0m |\n",
            "| \u001b[0m 151     \u001b[0m | \u001b[0m-2.861e+0\u001b[0m | \u001b[0m 24.92   \u001b[0m | \u001b[0m 14.82   \u001b[0m | \u001b[0m 0.9327  \u001b[0m | \u001b[0m 98.62   \u001b[0m |\n",
            "| \u001b[0m 152     \u001b[0m | \u001b[0m-2.919e+0\u001b[0m | \u001b[0m 11.88   \u001b[0m | \u001b[0m 19.23   \u001b[0m | \u001b[0m 0.07981 \u001b[0m | \u001b[0m 94.02   \u001b[0m |\n",
            "| \u001b[0m 153     \u001b[0m | \u001b[0m-2.872e+0\u001b[0m | \u001b[0m 12.77   \u001b[0m | \u001b[0m 19.05   \u001b[0m | \u001b[0m 0.04917 \u001b[0m | \u001b[0m 97.76   \u001b[0m |\n",
            "| \u001b[0m 154     \u001b[0m | \u001b[0m-2.914e+0\u001b[0m | \u001b[0m 11.82   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 91.19   \u001b[0m |\n",
            "| \u001b[0m 155     \u001b[0m | \u001b[0m-2.856e+0\u001b[0m | \u001b[0m 23.07   \u001b[0m | \u001b[0m 14.19   \u001b[0m | \u001b[0m 0.003883\u001b[0m | \u001b[0m 99.96   \u001b[0m |\n",
            "| \u001b[0m 156     \u001b[0m | \u001b[0m-2.872e+0\u001b[0m | \u001b[0m 12.96   \u001b[0m | \u001b[0m 19.91   \u001b[0m | \u001b[0m 0.4315  \u001b[0m | \u001b[0m 97.25   \u001b[0m |\n",
            "| \u001b[0m 157     \u001b[0m | \u001b[0m-2.937e+0\u001b[0m | \u001b[0m 24.88   \u001b[0m | \u001b[0m 15.15   \u001b[0m | \u001b[0m 0.9654  \u001b[0m | \u001b[0m 96.93   \u001b[0m |\n",
            "| \u001b[0m 158     \u001b[0m | \u001b[0m-2.913e+0\u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 18.03   \u001b[0m | \u001b[0m 0.7987  \u001b[0m | \u001b[0m 94.11   \u001b[0m |\n",
            "| \u001b[0m 159     \u001b[0m | \u001b[0m-2.927e+0\u001b[0m | \u001b[0m 12.77   \u001b[0m | \u001b[0m 17.46   \u001b[0m | \u001b[0m 0.07643 \u001b[0m | \u001b[0m 98.25   \u001b[0m |\n",
            "| \u001b[0m 160     \u001b[0m | \u001b[0m-2.87e+04\u001b[0m | \u001b[0m 12.84   \u001b[0m | \u001b[0m 19.95   \u001b[0m | \u001b[0m 0.1335  \u001b[0m | \u001b[0m 98.81   \u001b[0m |\n",
            "| \u001b[0m 161     \u001b[0m | \u001b[0m-2.893e+0\u001b[0m | \u001b[0m 13.3    \u001b[0m | \u001b[0m 19.4    \u001b[0m | \u001b[0m 0.983   \u001b[0m | \u001b[0m 90.89   \u001b[0m |\n",
            "| \u001b[0m 162     \u001b[0m | \u001b[0m-2.853e+0\u001b[0m | \u001b[0m 15.37   \u001b[0m | \u001b[0m 18.67   \u001b[0m | \u001b[0m 0.8017  \u001b[0m | \u001b[0m 80.24   \u001b[0m |\n",
            "| \u001b[0m 163     \u001b[0m | \u001b[0m-2.883e+0\u001b[0m | \u001b[0m 13.16   \u001b[0m | \u001b[0m 18.12   \u001b[0m | \u001b[0m 0.33    \u001b[0m | \u001b[0m 92.24   \u001b[0m |\n",
            "| \u001b[0m 164     \u001b[0m | \u001b[0m-2.89e+04\u001b[0m | \u001b[0m 13.35   \u001b[0m | \u001b[0m 19.56   \u001b[0m | \u001b[0m 0.9955  \u001b[0m | \u001b[0m 97.53   \u001b[0m |\n",
            "| \u001b[0m 165     \u001b[0m | \u001b[0m-2.983e+0\u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 85.6    \u001b[0m |\n",
            "| \u001b[0m 166     \u001b[0m | \u001b[0m-2.904e+0\u001b[0m | \u001b[0m 15.63   \u001b[0m | \u001b[0m 19.01   \u001b[0m | \u001b[0m 0.02633 \u001b[0m | \u001b[0m 80.04   \u001b[0m |\n",
            "| \u001b[0m 167     \u001b[0m | \u001b[0m-2.909e+0\u001b[0m | \u001b[0m 14.94   \u001b[0m | \u001b[0m 18.14   \u001b[0m | \u001b[0m 0.918   \u001b[0m | \u001b[0m 80.02   \u001b[0m |\n",
            "| \u001b[0m 168     \u001b[0m | \u001b[0m-2.853e+0\u001b[0m | \u001b[0m 15.75   \u001b[0m | \u001b[0m 18.13   \u001b[0m | \u001b[0m 0.02219 \u001b[0m | \u001b[0m 80.51   \u001b[0m |\n",
            "| \u001b[95m 169     \u001b[0m | \u001b[95m-2.844e+0\u001b[0m | \u001b[95m 22.34   \u001b[0m | \u001b[95m 14.72   \u001b[0m | \u001b[95m 0.2479  \u001b[0m | \u001b[95m 98.64   \u001b[0m |\n",
            "| \u001b[95m 170     \u001b[0m | \u001b[95m-2.843e+0\u001b[0m | \u001b[95m 22.58   \u001b[0m | \u001b[95m 14.73   \u001b[0m | \u001b[95m 0.09646 \u001b[0m | \u001b[95m 97.92   \u001b[0m |\n",
            "| \u001b[0m 171     \u001b[0m | \u001b[0m-2.964e+0\u001b[0m | \u001b[0m 21.98   \u001b[0m | \u001b[0m 15.36   \u001b[0m | \u001b[0m 0.3448  \u001b[0m | \u001b[0m 97.86   \u001b[0m |\n",
            "| \u001b[0m 172     \u001b[0m | \u001b[0m-2.856e+0\u001b[0m | \u001b[0m 23.09   \u001b[0m | \u001b[0m 14.55   \u001b[0m | \u001b[0m 0.5981  \u001b[0m | \u001b[0m 98.69   \u001b[0m |\n",
            "| \u001b[0m 173     \u001b[0m | \u001b[0m-2.844e+0\u001b[0m | \u001b[0m 22.68   \u001b[0m | \u001b[0m 14.59   \u001b[0m | \u001b[0m 0.4372  \u001b[0m | \u001b[0m 98.17   \u001b[0m |\n",
            "| \u001b[0m 174     \u001b[0m | \u001b[0m-2.844e+0\u001b[0m | \u001b[0m 22.74   \u001b[0m | \u001b[0m 14.42   \u001b[0m | \u001b[0m 0.02986 \u001b[0m | \u001b[0m 98.45   \u001b[0m |\n",
            "| \u001b[0m 175     \u001b[0m | \u001b[0m-2.909e+0\u001b[0m | \u001b[0m 22.68   \u001b[0m | \u001b[0m 13.94   \u001b[0m | \u001b[0m 0.06073 \u001b[0m | \u001b[0m 97.66   \u001b[0m |\n",
            "| \u001b[0m 176     \u001b[0m | \u001b[0m-2.923e+0\u001b[0m | \u001b[0m 22.95   \u001b[0m | \u001b[0m 15.3    \u001b[0m | \u001b[0m 0.1521  \u001b[0m | \u001b[0m 98.32   \u001b[0m |\n",
            "| \u001b[0m 177     \u001b[0m | \u001b[0m-2.844e+0\u001b[0m | \u001b[0m 22.12   \u001b[0m | \u001b[0m 14.38   \u001b[0m | \u001b[0m 0.04509 \u001b[0m | \u001b[0m 98.05   \u001b[0m |\n",
            "| \u001b[0m 178     \u001b[0m | \u001b[0m-2.844e+0\u001b[0m | \u001b[0m 22.75   \u001b[0m | \u001b[0m 14.55   \u001b[0m | \u001b[0m 0.03358 \u001b[0m | \u001b[0m 98.83   \u001b[0m |\n",
            "| \u001b[0m 179     \u001b[0m | \u001b[0m-2.927e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 89.0    \u001b[0m |\n",
            "| \u001b[0m 180     \u001b[0m | \u001b[0m-2.915e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 80.0    \u001b[0m |\n",
            "| \u001b[0m 181     \u001b[0m | \u001b[0m-2.853e+0\u001b[0m | \u001b[0m 15.79   \u001b[0m | \u001b[0m 18.56   \u001b[0m | \u001b[0m 0.7099  \u001b[0m | \u001b[0m 80.36   \u001b[0m |\n",
            "| \u001b[0m 182     \u001b[0m | \u001b[0m-2.891e+0\u001b[0m | \u001b[0m 24.98   \u001b[0m | \u001b[0m 19.91   \u001b[0m | \u001b[0m 0.1936  \u001b[0m | \u001b[0m 93.81   \u001b[0m |\n",
            "| \u001b[0m 183     \u001b[0m | \u001b[0m-2.868e+0\u001b[0m | \u001b[0m 23.37   \u001b[0m | \u001b[0m 19.27   \u001b[0m | \u001b[0m 0.1689  \u001b[0m | \u001b[0m 94.63   \u001b[0m |\n",
            "| \u001b[0m 184     \u001b[0m | \u001b[0m-2.922e+0\u001b[0m | \u001b[0m 23.63   \u001b[0m | \u001b[0m 18.52   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 93.94   \u001b[0m |\n",
            "| \u001b[0m 185     \u001b[0m | \u001b[0m-2.885e+0\u001b[0m | \u001b[0m 23.23   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.3337  \u001b[0m | \u001b[0m 95.25   \u001b[0m |\n",
            "| \u001b[0m 186     \u001b[0m | \u001b[0m-2.89e+04\u001b[0m | \u001b[0m 22.78   \u001b[0m | \u001b[0m 18.79   \u001b[0m | \u001b[0m 0.3049  \u001b[0m | \u001b[0m 95.3    \u001b[0m |\n",
            "| \u001b[0m 187     \u001b[0m | \u001b[0m-2.845e+0\u001b[0m | \u001b[0m 22.69   \u001b[0m | \u001b[0m 14.63   \u001b[0m | \u001b[0m 0.04476 \u001b[0m | \u001b[0m 99.41   \u001b[0m |\n",
            "| \u001b[0m 188     \u001b[0m | \u001b[0m-2.887e+0\u001b[0m | \u001b[0m 24.1    \u001b[0m | \u001b[0m 19.4    \u001b[0m | \u001b[0m 0.9451  \u001b[0m | \u001b[0m 94.93   \u001b[0m |\n",
            "| \u001b[0m 189     \u001b[0m | \u001b[0m-2.895e+0\u001b[0m | \u001b[0m 22.57   \u001b[0m | \u001b[0m 19.96   \u001b[0m | \u001b[0m 0.3987  \u001b[0m | \u001b[0m 94.32   \u001b[0m |\n",
            "| \u001b[0m 190     \u001b[0m | \u001b[0m-2.888e+0\u001b[0m | \u001b[0m 24.67   \u001b[0m | \u001b[0m 19.63   \u001b[0m | \u001b[0m 0.05494 \u001b[0m | \u001b[0m 96.67   \u001b[0m |\n",
            "| \u001b[0m 191     \u001b[0m | \u001b[0m-2.865e+0\u001b[0m | \u001b[0m 23.11   \u001b[0m | \u001b[0m 19.72   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 97.06   \u001b[0m |\n",
            "| \u001b[0m 192     \u001b[0m | \u001b[0m-2.865e+0\u001b[0m | \u001b[0m 23.07   \u001b[0m | \u001b[0m 19.74   \u001b[0m | \u001b[0m 0.4877  \u001b[0m | \u001b[0m 97.98   \u001b[0m |\n",
            "| \u001b[0m 193     \u001b[0m | \u001b[0m-2.914e+0\u001b[0m | \u001b[0m 23.47   \u001b[0m | \u001b[0m 18.98   \u001b[0m | \u001b[0m 0.02639 \u001b[0m | \u001b[0m 97.68   \u001b[0m |\n",
            "| \u001b[0m 194     \u001b[0m | \u001b[0m-2.905e+0\u001b[0m | \u001b[0m 22.51   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.6894  \u001b[0m | \u001b[0m 97.27   \u001b[0m |\n",
            "| \u001b[0m 195     \u001b[0m | \u001b[0m-2.908e+0\u001b[0m | \u001b[0m 22.91   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 98.7    \u001b[0m |\n",
            "| \u001b[0m 196     \u001b[0m | \u001b[0m-2.881e+0\u001b[0m | \u001b[0m 23.75   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.6416  \u001b[0m | \u001b[0m 97.48   \u001b[0m |\n",
            "| \u001b[0m 197     \u001b[0m | \u001b[0m-2.844e+0\u001b[0m | \u001b[0m 22.39   \u001b[0m | \u001b[0m 14.74   \u001b[0m | \u001b[0m 0.02051 \u001b[0m | \u001b[0m 98.29   \u001b[0m |\n",
            "| \u001b[0m 198     \u001b[0m | \u001b[0m-2.91e+04\u001b[0m | \u001b[0m 24.31   \u001b[0m | \u001b[0m 18.68   \u001b[0m | \u001b[0m 0.04868 \u001b[0m | \u001b[0m 95.52   \u001b[0m |\n",
            "| \u001b[0m 199     \u001b[0m | \u001b[0m-2.899e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 98.6    \u001b[0m |\n",
            "| \u001b[0m 200     \u001b[0m | \u001b[0m-2.924e+0\u001b[0m | \u001b[0m 24.19   \u001b[0m | \u001b[0m 15.02   \u001b[0m | \u001b[0m 0.9349  \u001b[0m | \u001b[0m 80.11   \u001b[0m |\n",
            "| \u001b[0m 201     \u001b[0m | \u001b[0m-2.86e+04\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 14.54   \u001b[0m | \u001b[0m 0.3456  \u001b[0m | \u001b[0m 98.65   \u001b[0m |\n",
            "| \u001b[0m 202     \u001b[0m | \u001b[0m-2.866e+0\u001b[0m | \u001b[0m 23.72   \u001b[0m | \u001b[0m 19.99   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 96.33   \u001b[0m |\n",
            "| \u001b[0m 203     \u001b[0m | \u001b[0m-2.937e+0\u001b[0m | \u001b[0m 18.19   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 94.69   \u001b[0m |\n",
            "| \u001b[0m 204     \u001b[0m | \u001b[0m-2.907e+0\u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 83.16   \u001b[0m |\n",
            "| \u001b[0m 205     \u001b[0m | \u001b[0m-2.949e+0\u001b[0m | \u001b[0m 20.88   \u001b[0m | \u001b[0m 13.2    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 91.29   \u001b[0m |\n",
            "| \u001b[0m 206     \u001b[0m | \u001b[0m-2.899e+0\u001b[0m | \u001b[0m 24.93   \u001b[0m | \u001b[0m 19.71   \u001b[0m | \u001b[0m 0.7239  \u001b[0m | \u001b[0m 84.92   \u001b[0m |\n",
            "| \u001b[0m 207     \u001b[0m | \u001b[0m-2.864e+0\u001b[0m | \u001b[0m 23.47   \u001b[0m | \u001b[0m 19.53   \u001b[0m | \u001b[0m 0.9883  \u001b[0m | \u001b[0m 96.6    \u001b[0m |\n",
            "| \u001b[0m 208     \u001b[0m | \u001b[0m-2.89e+04\u001b[0m | \u001b[0m 22.62   \u001b[0m | \u001b[0m 18.81   \u001b[0m | \u001b[0m 0.9123  \u001b[0m | \u001b[0m 96.46   \u001b[0m |\n",
            "| \u001b[0m 209     \u001b[0m | \u001b[0m-2.927e+0\u001b[0m | \u001b[0m 22.54   \u001b[0m | \u001b[0m 10.05   \u001b[0m | \u001b[0m 0.6898  \u001b[0m | \u001b[0m 84.75   \u001b[0m |\n",
            "| \u001b[0m 210     \u001b[0m | \u001b[0m-2.895e+0\u001b[0m | \u001b[0m 22.53   \u001b[0m | \u001b[0m 19.11   \u001b[0m | \u001b[0m 0.9994  \u001b[0m | \u001b[0m 98.67   \u001b[0m |\n",
            "| \u001b[0m 211     \u001b[0m | \u001b[0m-2.886e+0\u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 19.79   \u001b[0m | \u001b[0m 0.8973  \u001b[0m | \u001b[0m 96.5    \u001b[0m |\n",
            "| \u001b[0m 212     \u001b[0m | \u001b[0m-2.891e+0\u001b[0m | \u001b[0m 22.95   \u001b[0m | \u001b[0m 19.3    \u001b[0m | \u001b[0m 0.1932  \u001b[0m | \u001b[0m 96.38   \u001b[0m |\n",
            "| \u001b[0m 213     \u001b[0m | \u001b[0m-2.98e+04\u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 80.0    \u001b[0m |\n",
            "| \u001b[0m 214     \u001b[0m | \u001b[0m-2.968e+0\u001b[0m | \u001b[0m 10.3    \u001b[0m | \u001b[0m 10.06   \u001b[0m | \u001b[0m 0.7974  \u001b[0m | \u001b[0m 97.34   \u001b[0m |\n",
            "| \u001b[0m 215     \u001b[0m | \u001b[0m-2.928e+0\u001b[0m | \u001b[0m 17.22   \u001b[0m | \u001b[0m 13.86   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 97.21   \u001b[0m |\n",
            "| \u001b[0m 216     \u001b[0m | \u001b[0m-2.966e+0\u001b[0m | \u001b[0m 10.04   \u001b[0m | \u001b[0m 15.28   \u001b[0m | \u001b[0m 0.6897  \u001b[0m | \u001b[0m 85.13   \u001b[0m |\n",
            "| \u001b[0m 217     \u001b[0m | \u001b[0m-2.861e+0\u001b[0m | \u001b[0m 24.83   \u001b[0m | \u001b[0m 14.35   \u001b[0m | \u001b[0m 0.9897  \u001b[0m | \u001b[0m 92.38   \u001b[0m |\n",
            "| \u001b[0m 218     \u001b[0m | \u001b[0m-2.873e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 14.19   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 91.43   \u001b[0m |\n",
            "| \u001b[0m 219     \u001b[0m | \u001b[0m-2.861e+0\u001b[0m | \u001b[0m 24.11   \u001b[0m | \u001b[0m 14.84   \u001b[0m | \u001b[0m 0.681   \u001b[0m | \u001b[0m 91.97   \u001b[0m |\n",
            "| \u001b[0m 220     \u001b[0m | \u001b[0m-2.859e+0\u001b[0m | \u001b[0m 24.93   \u001b[0m | \u001b[0m 14.77   \u001b[0m | \u001b[0m 0.1068  \u001b[0m | \u001b[0m 92.13   \u001b[0m |\n",
            "| \u001b[0m 221     \u001b[0m | \u001b[0m-2.935e+0\u001b[0m | \u001b[0m 24.99   \u001b[0m | \u001b[0m 15.37   \u001b[0m | \u001b[0m 0.8659  \u001b[0m | \u001b[0m 92.53   \u001b[0m |\n",
            "| \u001b[0m 222     \u001b[0m | \u001b[0m-2.912e+0\u001b[0m | \u001b[0m 24.07   \u001b[0m | \u001b[0m 13.9    \u001b[0m | \u001b[0m 0.439   \u001b[0m | \u001b[0m 91.94   \u001b[0m |\n",
            "| \u001b[0m 223     \u001b[0m | \u001b[0m-2.927e+0\u001b[0m | \u001b[0m 23.61   \u001b[0m | \u001b[0m 15.31   \u001b[0m | \u001b[0m 0.7272  \u001b[0m | \u001b[0m 91.32   \u001b[0m |\n",
            "| \u001b[0m 224     \u001b[0m | \u001b[0m-2.859e+0\u001b[0m | \u001b[0m 24.53   \u001b[0m | \u001b[0m 14.67   \u001b[0m | \u001b[0m 0.07302 \u001b[0m | \u001b[0m 93.05   \u001b[0m |\n",
            "| \u001b[0m 225     \u001b[0m | \u001b[0m-2.926e+0\u001b[0m | \u001b[0m 23.92   \u001b[0m | \u001b[0m 15.24   \u001b[0m | \u001b[0m 0.04927 \u001b[0m | \u001b[0m 92.62   \u001b[0m |\n",
            "| \u001b[0m 226     \u001b[0m | \u001b[0m-2.86e+04\u001b[0m | \u001b[0m 24.82   \u001b[0m | \u001b[0m 14.2    \u001b[0m | \u001b[0m 0.5013  \u001b[0m | \u001b[0m 93.37   \u001b[0m |\n",
            "| \u001b[0m 227     \u001b[0m | \u001b[0m-2.859e+0\u001b[0m | \u001b[0m 24.89   \u001b[0m | \u001b[0m 14.48   \u001b[0m | \u001b[0m 0.03647 \u001b[0m | \u001b[0m 92.78   \u001b[0m |\n",
            "| \u001b[0m 228     \u001b[0m | \u001b[0m-2.86e+04\u001b[0m | \u001b[0m 24.88   \u001b[0m | \u001b[0m 14.63   \u001b[0m | \u001b[0m 0.0183  \u001b[0m | \u001b[0m 94.33   \u001b[0m |\n",
            "| \u001b[0m 229     \u001b[0m | \u001b[0m-2.859e+0\u001b[0m | \u001b[0m 24.25   \u001b[0m | \u001b[0m 14.1    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 93.87   \u001b[0m |\n",
            "| \u001b[0m 230     \u001b[0m | \u001b[0m-2.861e+0\u001b[0m | \u001b[0m 24.18   \u001b[0m | \u001b[0m 14.19   \u001b[0m | \u001b[0m 0.8938  \u001b[0m | \u001b[0m 94.33   \u001b[0m |\n",
            "| \u001b[0m 231     \u001b[0m | \u001b[0m-2.913e+0\u001b[0m | \u001b[0m 24.68   \u001b[0m | \u001b[0m 13.42   \u001b[0m | \u001b[0m 0.2816  \u001b[0m | \u001b[0m 94.46   \u001b[0m |\n",
            "| \u001b[0m 232     \u001b[0m | \u001b[0m-2.929e+0\u001b[0m | \u001b[0m 23.83   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.9128  \u001b[0m | \u001b[0m 94.35   \u001b[0m |\n",
            "| \u001b[0m 233     \u001b[0m | \u001b[0m-2.861e+0\u001b[0m | \u001b[0m 24.25   \u001b[0m | \u001b[0m 14.29   \u001b[0m | \u001b[0m 0.9944  \u001b[0m | \u001b[0m 92.97   \u001b[0m |\n",
            "| \u001b[0m 234     \u001b[0m | \u001b[0m-2.915e+0\u001b[0m | \u001b[0m 23.37   \u001b[0m | \u001b[0m 13.37   \u001b[0m | \u001b[0m 0.762   \u001b[0m | \u001b[0m 94.11   \u001b[0m |\n",
            "| \u001b[0m 235     \u001b[0m | \u001b[0m-2.856e+0\u001b[0m | \u001b[0m 24.73   \u001b[0m | \u001b[0m 14.37   \u001b[0m | \u001b[0m 0.261   \u001b[0m | \u001b[0m 90.4    \u001b[0m |\n",
            "| \u001b[0m 236     \u001b[0m | \u001b[0m-2.935e+0\u001b[0m | \u001b[0m 24.95   \u001b[0m | \u001b[0m 15.1    \u001b[0m | \u001b[0m 0.4849  \u001b[0m | \u001b[0m 89.9    \u001b[0m |\n",
            "| \u001b[0m 237     \u001b[0m | \u001b[0m-2.912e+0\u001b[0m | \u001b[0m 24.91   \u001b[0m | \u001b[0m 13.3    \u001b[0m | \u001b[0m 0.2908  \u001b[0m | \u001b[0m 89.98   \u001b[0m |\n",
            "| \u001b[0m 238     \u001b[0m | \u001b[0m-2.861e+0\u001b[0m | \u001b[0m 24.62   \u001b[0m | \u001b[0m 14.94   \u001b[0m | \u001b[0m 0.6089  \u001b[0m | \u001b[0m 91.26   \u001b[0m |\n",
            "| \u001b[0m 239     \u001b[0m | \u001b[0m-2.861e+0\u001b[0m | \u001b[0m 24.54   \u001b[0m | \u001b[0m 14.36   \u001b[0m | \u001b[0m 0.1977  \u001b[0m | \u001b[0m 91.36   \u001b[0m |\n",
            "| \u001b[0m 240     \u001b[0m | \u001b[0m-2.861e+0\u001b[0m | \u001b[0m 24.36   \u001b[0m | \u001b[0m 14.05   \u001b[0m | \u001b[0m 0.9764  \u001b[0m | \u001b[0m 93.54   \u001b[0m |\n",
            "| \u001b[0m 241     \u001b[0m | \u001b[0m-2.856e+0\u001b[0m | \u001b[0m 24.52   \u001b[0m | \u001b[0m 14.33   \u001b[0m | \u001b[0m 0.8382  \u001b[0m | \u001b[0m 90.72   \u001b[0m |\n",
            "| \u001b[0m 242     \u001b[0m | \u001b[0m-2.927e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
            "| \u001b[0m 243     \u001b[0m | \u001b[0m-2.861e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 14.41   \u001b[0m | \u001b[0m 0.8521  \u001b[0m | \u001b[0m 94.48   \u001b[0m |\n",
            "| \u001b[0m 244     \u001b[0m | \u001b[0m-2.851e+0\u001b[0m | \u001b[0m 23.64   \u001b[0m | \u001b[0m 14.41   \u001b[0m | \u001b[0m 0.2165  \u001b[0m | \u001b[0m 90.07   \u001b[0m |\n",
            "| \u001b[0m 245     \u001b[0m | \u001b[0m-2.855e+0\u001b[0m | \u001b[0m 24.06   \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 90.54   \u001b[0m |\n",
            "| \u001b[0m 246     \u001b[0m | \u001b[0m-2.915e+0\u001b[0m | \u001b[0m 23.67   \u001b[0m | \u001b[0m 13.92   \u001b[0m | \u001b[0m 0.8395  \u001b[0m | \u001b[0m 90.12   \u001b[0m |\n",
            "| \u001b[95m 247     \u001b[0m | \u001b[95m-2.836e+0\u001b[0m | \u001b[95m 22.8    \u001b[0m | \u001b[95m 14.65   \u001b[0m | \u001b[95m 0.3069  \u001b[0m | \u001b[95m 89.92   \u001b[0m |\n",
            "| \u001b[0m 248     \u001b[0m | \u001b[0m-2.85e+04\u001b[0m | \u001b[0m 23.1    \u001b[0m | \u001b[0m 14.78   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 89.46   \u001b[0m |\n",
            "| \u001b[95m 249     \u001b[0m | \u001b[95m-2.835e+0\u001b[0m | \u001b[95m 22.77   \u001b[0m | \u001b[95m 14.14   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 89.82   \u001b[0m |\n",
            "| \u001b[0m 250     \u001b[0m | \u001b[0m-2.92e+04\u001b[0m | \u001b[0m 22.32   \u001b[0m | \u001b[0m 15.03   \u001b[0m | \u001b[0m 0.07138 \u001b[0m | \u001b[0m 89.74   \u001b[0m |\n",
            "| \u001b[0m 251     \u001b[0m | \u001b[0m-2.85e+04\u001b[0m | \u001b[0m 23.13   \u001b[0m | \u001b[0m 14.58   \u001b[0m | \u001b[0m 0.5024  \u001b[0m | \u001b[0m 89.17   \u001b[0m |\n",
            "| \u001b[0m 252     \u001b[0m | \u001b[0m-2.836e+0\u001b[0m | \u001b[0m 22.73   \u001b[0m | \u001b[0m 14.18   \u001b[0m | \u001b[0m 0.5437  \u001b[0m | \u001b[0m 89.63   \u001b[0m |\n",
            "| \u001b[0m 253     \u001b[0m | \u001b[0m-2.85e+04\u001b[0m | \u001b[0m 23.24   \u001b[0m | \u001b[0m 14.07   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 89.4    \u001b[0m |\n",
            "| \u001b[0m 254     \u001b[0m | \u001b[0m-2.914e+0\u001b[0m | \u001b[0m 21.99   \u001b[0m | \u001b[0m 13.75   \u001b[0m | \u001b[0m 0.341   \u001b[0m | \u001b[0m 89.29   \u001b[0m |\n",
            "| \u001b[0m 255     \u001b[0m | \u001b[0m-2.84e+04\u001b[0m | \u001b[0m 22.8    \u001b[0m | \u001b[0m 14.36   \u001b[0m | \u001b[0m 0.4114  \u001b[0m | \u001b[0m 90.29   \u001b[0m |\n",
            "| \u001b[0m 256     \u001b[0m | \u001b[0m-2.908e+0\u001b[0m | \u001b[0m 22.86   \u001b[0m | \u001b[0m 13.51   \u001b[0m | \u001b[0m 0.06174 \u001b[0m | \u001b[0m 90.37   \u001b[0m |\n",
            "| \u001b[0m 257     \u001b[0m | \u001b[0m-2.852e+0\u001b[0m | \u001b[0m 23.11   \u001b[0m | \u001b[0m 14.57   \u001b[0m | \u001b[0m 0.001069\u001b[0m | \u001b[0m 88.48   \u001b[0m |\n",
            "| \u001b[0m 258     \u001b[0m | \u001b[0m-2.853e+0\u001b[0m | \u001b[0m 23.87   \u001b[0m | \u001b[0m 14.3    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 88.17   \u001b[0m |\n",
            "| \u001b[0m 259     \u001b[0m | \u001b[0m-2.918e+0\u001b[0m | \u001b[0m 23.23   \u001b[0m | \u001b[0m 13.78   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 87.93   \u001b[0m |\n",
            "| \u001b[0m 260     \u001b[0m | \u001b[0m-2.853e+0\u001b[0m | \u001b[0m 23.8    \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 88.56   \u001b[0m |\n",
            "| \u001b[0m 261     \u001b[0m | \u001b[0m-2.852e+0\u001b[0m | \u001b[0m 23.84   \u001b[0m | \u001b[0m 14.8    \u001b[0m | \u001b[0m 0.7077  \u001b[0m | \u001b[0m 88.22   \u001b[0m |\n",
            "| \u001b[0m 262     \u001b[0m | \u001b[0m-2.933e+0\u001b[0m | \u001b[0m 24.01   \u001b[0m | \u001b[0m 15.45   \u001b[0m | \u001b[0m 0.2949  \u001b[0m | \u001b[0m 87.59   \u001b[0m |\n",
            "| \u001b[0m 263     \u001b[0m | \u001b[0m-2.849e+0\u001b[0m | \u001b[0m 23.52   \u001b[0m | \u001b[0m 14.67   \u001b[0m | \u001b[0m 0.1701  \u001b[0m | \u001b[0m 89.08   \u001b[0m |\n",
            "| \u001b[0m 264     \u001b[0m | \u001b[0m-2.858e+0\u001b[0m | \u001b[0m 24.83   \u001b[0m | \u001b[0m 14.17   \u001b[0m | \u001b[0m 0.3443  \u001b[0m | \u001b[0m 88.34   \u001b[0m |\n",
            "| \u001b[0m 265     \u001b[0m | \u001b[0m-2.857e+0\u001b[0m | \u001b[0m 24.37   \u001b[0m | \u001b[0m 14.5    \u001b[0m | \u001b[0m 0.898   \u001b[0m | \u001b[0m 88.49   \u001b[0m |\n",
            "| \u001b[0m 266     \u001b[0m | \u001b[0m-2.909e+0\u001b[0m | \u001b[0m 24.65   \u001b[0m | \u001b[0m 13.69   \u001b[0m | \u001b[0m 0.3106  \u001b[0m | \u001b[0m 87.35   \u001b[0m |\n",
            "| \u001b[0m 267     \u001b[0m | \u001b[0m-2.841e+0\u001b[0m | \u001b[0m 22.86   \u001b[0m | \u001b[0m 14.78   \u001b[0m | \u001b[0m 0.9396  \u001b[0m | \u001b[0m 88.5    \u001b[0m |\n",
            "| \u001b[0m 268     \u001b[0m | \u001b[0m-2.852e+0\u001b[0m | \u001b[0m 23.24   \u001b[0m | \u001b[0m 14.61   \u001b[0m | \u001b[0m 0.8546  \u001b[0m | \u001b[0m 88.18   \u001b[0m |\n",
            "| \u001b[0m 269     \u001b[0m | \u001b[0m-2.841e+0\u001b[0m | \u001b[0m 22.77   \u001b[0m | \u001b[0m 14.62   \u001b[0m | \u001b[0m 0.9389  \u001b[0m | \u001b[0m 90.12   \u001b[0m |\n",
            "| \u001b[0m 270     \u001b[0m | \u001b[0m-2.93e+04\u001b[0m | \u001b[0m 23.3    \u001b[0m | \u001b[0m 15.33   \u001b[0m | \u001b[0m 0.912   \u001b[0m | \u001b[0m 88.89   \u001b[0m |\n",
            "| \u001b[0m 271     \u001b[0m | \u001b[0m-2.84e+04\u001b[0m | \u001b[0m 22.53   \u001b[0m | \u001b[0m 14.24   \u001b[0m | \u001b[0m 0.797   \u001b[0m | \u001b[0m 88.73   \u001b[0m |\n",
            "| \u001b[0m 272     \u001b[0m | \u001b[0m-2.905e+0\u001b[0m | \u001b[0m 21.9    \u001b[0m | \u001b[0m 14.54   \u001b[0m | \u001b[0m 0.5857  \u001b[0m | \u001b[0m 87.91   \u001b[0m |\n",
            "| \u001b[0m 273     \u001b[0m | \u001b[0m-2.852e+0\u001b[0m | \u001b[0m 23.74   \u001b[0m | \u001b[0m 14.29   \u001b[0m | \u001b[0m 0.86    \u001b[0m | \u001b[0m 88.47   \u001b[0m |\n",
            "| \u001b[0m 274     \u001b[0m | \u001b[0m-2.837e+0\u001b[0m | \u001b[0m 22.28   \u001b[0m | \u001b[0m 14.62   \u001b[0m | \u001b[0m 0.9523  \u001b[0m | \u001b[0m 89.16   \u001b[0m |\n",
            "| \u001b[0m 275     \u001b[0m | \u001b[0m-2.908e+0\u001b[0m | \u001b[0m 24.15   \u001b[0m | \u001b[0m 13.91   \u001b[0m | \u001b[0m 0.05677 \u001b[0m | \u001b[0m 88.88   \u001b[0m |\n",
            "| \u001b[0m 276     \u001b[0m | \u001b[0m-2.858e+0\u001b[0m | \u001b[0m 24.76   \u001b[0m | \u001b[0m 14.84   \u001b[0m | \u001b[0m 0.3275  \u001b[0m | \u001b[0m 88.16   \u001b[0m |\n",
            "| \u001b[0m 277     \u001b[0m | \u001b[0m-2.836e+0\u001b[0m | \u001b[0m 22.96   \u001b[0m | \u001b[0m 14.25   \u001b[0m | \u001b[0m 0.4754  \u001b[0m | \u001b[0m 89.87   \u001b[0m |\n",
            "| \u001b[0m 278     \u001b[0m | \u001b[0m-2.939e+0\u001b[0m | \u001b[0m 15.1    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 98.37   \u001b[0m |\n",
            "| \u001b[0m 279     \u001b[0m | \u001b[0m-2.836e+0\u001b[0m | \u001b[0m 22.84   \u001b[0m | \u001b[0m 14.38   \u001b[0m | \u001b[0m 0.8515  \u001b[0m | \u001b[0m 89.17   \u001b[0m |\n",
            "| \u001b[0m 280     \u001b[0m | \u001b[0m-2.971e+0\u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 17.82   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 80.0    \u001b[0m |\n",
            "| \u001b[0m 281     \u001b[0m | \u001b[0m-2.982e+0\u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 89.99   \u001b[0m |\n",
            "| \u001b[0m 282     \u001b[0m | \u001b[0m-2.97e+04\u001b[0m | \u001b[0m 13.98   \u001b[0m | \u001b[0m 10.21   \u001b[0m | \u001b[0m 0.0337  \u001b[0m | \u001b[0m 84.75   \u001b[0m |\n",
            "| \u001b[0m 283     \u001b[0m | \u001b[0m-2.849e+0\u001b[0m | \u001b[0m 23.02   \u001b[0m | \u001b[0m 14.42   \u001b[0m | \u001b[0m 0.0763  \u001b[0m | \u001b[0m 89.95   \u001b[0m |\n",
            "| \u001b[0m 284     \u001b[0m | \u001b[0m-2.968e+0\u001b[0m | \u001b[0m 21.22   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 80.0    \u001b[0m |\n",
            "| \u001b[0m 285     \u001b[0m | \u001b[0m-2.905e+0\u001b[0m | \u001b[0m 21.91   \u001b[0m | \u001b[0m 14.42   \u001b[0m | \u001b[0m 0.9744  \u001b[0m | \u001b[0m 90.57   \u001b[0m |\n",
            "| \u001b[0m 286     \u001b[0m | \u001b[0m-2.951e+0\u001b[0m | \u001b[0m 21.38   \u001b[0m | \u001b[0m 12.03   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 80.0    \u001b[0m |\n",
            "| \u001b[0m 287     \u001b[0m | \u001b[0m-2.872e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 16.98   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 83.25   \u001b[0m |\n",
            "| \u001b[0m 288     \u001b[0m | \u001b[0m-2.948e+0\u001b[0m | \u001b[0m 24.54   \u001b[0m | \u001b[0m 17.98   \u001b[0m | \u001b[0m 0.3718  \u001b[0m | \u001b[0m 82.82   \u001b[0m |\n",
            "| \u001b[0m 289     \u001b[0m | \u001b[0m-2.909e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 15.89   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 83.67   \u001b[0m |\n",
            "| \u001b[0m 290     \u001b[0m | \u001b[0m-2.971e+0\u001b[0m | \u001b[0m 20.52   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 88.21   \u001b[0m |\n",
            "| \u001b[0m 291     \u001b[0m | \u001b[0m-2.938e+0\u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 14.77   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 89.34   \u001b[0m |\n",
            "| \u001b[0m 292     \u001b[0m | \u001b[0m-2.934e+0\u001b[0m | \u001b[0m 10.13   \u001b[0m | \u001b[0m 14.54   \u001b[0m | \u001b[0m 0.3669  \u001b[0m | \u001b[0m 95.81   \u001b[0m |\n",
            "| \u001b[0m 293     \u001b[0m | \u001b[0m-2.976e+0\u001b[0m | \u001b[0m 19.17   \u001b[0m | \u001b[0m 15.27   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 94.48   \u001b[0m |\n",
            "| \u001b[0m 294     \u001b[0m | \u001b[0m-2.965e+0\u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 12.26   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 83.29   \u001b[0m |\n",
            "| \u001b[0m 295     \u001b[0m | \u001b[0m-2.888e+0\u001b[0m | \u001b[0m 24.84   \u001b[0m | \u001b[0m 19.87   \u001b[0m | \u001b[0m 0.8937  \u001b[0m | \u001b[0m 90.86   \u001b[0m |\n",
            "| \u001b[0m 296     \u001b[0m | \u001b[0m-2.961e+0\u001b[0m | \u001b[0m 13.87   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 94.86   \u001b[0m |\n",
            "| \u001b[0m 297     \u001b[0m | \u001b[0m-2.895e+0\u001b[0m | \u001b[0m 22.89   \u001b[0m | \u001b[0m 19.95   \u001b[0m | \u001b[0m 0.6566  \u001b[0m | \u001b[0m 91.44   \u001b[0m |\n",
            "| \u001b[0m 298     \u001b[0m | \u001b[0m-2.975e+0\u001b[0m | \u001b[0m 10.13   \u001b[0m | \u001b[0m 13.87   \u001b[0m | \u001b[0m 0.9502  \u001b[0m | \u001b[0m 81.74   \u001b[0m |\n",
            "| \u001b[0m 299     \u001b[0m | \u001b[0m-2.946e+0\u001b[0m | \u001b[0m 16.58   \u001b[0m | \u001b[0m 15.55   \u001b[0m | \u001b[0m 0.01365 \u001b[0m | \u001b[0m 99.89   \u001b[0m |\n",
            "| \u001b[0m 300     \u001b[0m | \u001b[0m-2.888e+0\u001b[0m | \u001b[0m 24.79   \u001b[0m | \u001b[0m 19.88   \u001b[0m | \u001b[0m 0.8136  \u001b[0m | \u001b[0m 88.76   \u001b[0m |\n",
            "=========================================================================\n",
            "\n",
            " \n",
            " best params:  {'max_depth': 22.76987255830374, 'max_features': 14.139404019924546, 'min_impurity_decrease': 0.0, 'n_estimators': 89.82134842869006} \n",
            " \n",
            " best cvscore:  -28346.672687223065\n",
            "It takes 2.107581957181295 minutes\n",
            "\n",
            " \n",
            " validation_score:  -28346.672687223065\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "params_best, score_best = param_bayes_opt(20,280) #初始看20个观测值，后面迭代280次\n",
        "print('It takes %s minutes' % ((time.time() - start)/60))\n",
        "validation_score = bayes_opt_validation(params_best)\n",
        "print(\"\\n\",\"\\n\",\"validation_score: \",validation_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e312350a-c7c6-4c82-8285-4dde59be5356",
      "metadata": {
        "id": "e312350a-c7c6-4c82-8285-4dde59be5356"
      },
      "source": [
        "|HPO方法|默认参数|网格搜索|随机搜索|随机搜索<br>(大空间)|随机搜索<br>(连续型)|贝叶斯优化<br>(基于GP)|\n",
        "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
        "|搜索空间/全域空间|-|1536/1536|800/1536|1536/3000|1536/无限|300/无限|\n",
        "|运行时间（分钟）|-|6.36|<font color=\"green\">**2.83(↓)**</font>|<font color=\"green\">**3.86(↓)**</font>|3.92|<font color=\"green\">**2.11(↓)**|\n",
        "|搜索最优（RMSE）|30571.266|29179.698|29251.284|<font color=\"green\">**29012.905(↓)**</font>|29148.381|<font color=\"green\">**28346.673(↓)**</font>|\n",
        "|重建最优（RMSE）|-|28572.070|<font color=\"brown\">**28639.969(↑)**</font>|<font color=\"green\">**28346.673(↓)**</font>|28495.682|<font color=\"green\">**28346.673(↓)**</font>|"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "890c1fe5-92eb-4534-8ea3-7a7ed7e9b823",
      "metadata": {
        "id": "890c1fe5-92eb-4534-8ea3-7a7ed7e9b823"
      },
      "source": [
        "- 原理上有优越性\n",
        "\n",
        "可以看到，基于高斯过程的贝叶斯优化在2.11分钟内锁定了最佳分数28346.673，这是之前使用随机搜索时获得的最佳分数，很可能也是我们当前超参数空间上可以获得的最佳分数。贝叶斯优化作为从原理上高于网格优化的HPO方法，能够以更短的时间获得与随机网格搜索相同的结果，可见其原理上的优越性。\n",
        "\n",
        "- 优化过程无法复现，但优化结果可以复现\n",
        "\n",
        "但同时要注意，由于贝叶斯优化每次都是随机的，因此我们并不能在多次运行代码时复现出28346.673这个结果，事实上如果我们重复运行，也只有很小的概率可以再次找到这个最低值（这一点对于随机搜索来说也是类似的，如果不规定随机数种子，我们也无法复现最低值）。因此我们在执行贝叶斯优化时，往往会多运行几次观察模型找出的结果。同时，验证分数与目标函数最后输出的分数一模一样，可见最终输出的超参数组合的效力是可以复现的。\n",
        "\n",
        "- 效率不足\n",
        "\n",
        "不难发现，bayes_opt的速度虽然快，效率却不高。实际上在迭代到170次时，贝叶斯优化就已经找到了最小损失，但由于没有提前停止机制，模型还持续地迭代了130次才停下，如果bayes_opt支持提前停止机制，贝叶斯优化所需的实际迭代时间可能会更少。同时，由于Bayes_opt只能够在参数空间提取浮点数，bayes_opt在随机森林上的搜索效率是较低的，即便在10次不同的迭代中分别取到了[88.89, 88.23, 88.16, 88.59……]等值，在取整之后也只能够获得一个备选值88，但bayes_opt无法辨别这种区别，因此可能取出了众多无效的观测点。如果使用其他贝叶斯优化器，贝叶斯优化的效率将会更高。\n",
        "\n",
        "- 支持灵活修改\n",
        "\n",
        "虽然在我们的代码中没有体现，但bayes_opt是支持灵活修改采集函数与高斯过程中的种种参数的，具体可以参考这里：https://github.com/fmfn/BayesianOptimization/blob/master/examples/advanced-tour.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34b6239d-dd5f-460d-9fdf-9212c18d1880",
      "metadata": {
        "id": "34b6239d-dd5f-460d-9fdf-9212c18d1880"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e60abf-3549-45e9-a821-e5b01a4cbe40",
      "metadata": {
        "tags": [],
        "id": "d0e60abf-3549-45e9-a821-e5b01a4cbe40"
      },
      "source": [
        "## 2 基于HyperOpt实现TPE优化"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cbbc10c-949c-4711-9b2d-f1caa7ebb03b",
      "metadata": {
        "id": "0cbbc10c-949c-4711-9b2d-f1caa7ebb03b"
      },
      "source": [
        "Hyperopt优化器是目前最为通用的贝叶斯优化器之一，Hyperopt中集成了包括随机搜索、模拟退火和TPE（Tree-structured Parzen Estimator Approach）等多种优化算法。相比于Bayes_opt，Hyperopt的是更先进、更现代、维护更好的优化器，也是我们最常用来实现TPE方法的优化器。在实际使用中，相比基于高斯过程的贝叶斯优化，基于高斯混合模型的TPE在大多数情况下以更高效率获得更优结果，该方法目前也被广泛应用于AutoML领域中。TPE算法原理可以参阅原论文[Multiobjective tree-structured parzen estimator for computationally expensive optimization problems](https://www.researchgate.net/publication/342537251_Multiobjective_tree-structured_parzen_estimator_for_computationally_expensive_optimization_problems)，在这里我们将重点介绍关于Hyperopt中使用TPE进行超参数搜索的过程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7d22253-afc7-44dc-a71b-5cd1ac0d488a",
      "metadata": {
        "id": "d7d22253-afc7-44dc-a71b-5cd1ac0d488a"
      },
      "outputs": [],
      "source": [
        "import hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials, partial\n",
        "from hyperopt.early_stop import no_progress_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ecb1f46-6d61-49e7-bdda-0ff964d7c06d",
      "metadata": {
        "id": "5ecb1f46-6d61-49e7-bdda-0ff964d7c06d",
        "outputId": "0187c79d-4570-4e65-f41d-d0c8463542b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2.7\n"
          ]
        }
      ],
      "source": [
        "print(hyperopt.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "057d933f-3227-43ef-8f99-2dfae34e1cf7",
      "metadata": {
        "id": "057d933f-3227-43ef-8f99-2dfae34e1cf7"
      },
      "source": [
        "- 1 定义目标函数"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "006baab0-72e9-431d-b88d-4bf4d171628e",
      "metadata": {
        "id": "006baab0-72e9-431d-b88d-4bf4d171628e"
      },
      "source": [
        "在定义目标函数$f(x)$时，我们需要严格遵守需要使用的当下优化库的基本规则。与Bayes_opt一样，Hyperopt也有一些特定的规则会限制我们的定义方式，主要包括：\n",
        "\n",
        "> 1 **目标函数的输入必须是符合hyperopt规定的字典**，不能是类似于sklearn的参数空间字典、不能是参数本身，更不能是数据、算法等超参数以外的元素。因此在自定义目标函数时，我们需要让超参数空间字典作为目标函数的输入。<br><br>\n",
        "> 2 **Hyperopt只支持寻找$f(x)$的最小值，不支持寻找最大值**，因此当我们定义的目标函数是某种正面的评估指标时（如准确率，auc），我们需要对该评估指标取负。如果我们定义的目标函数是负损失，也需要对负损失取绝对值。当且仅当我们定义的目标函数是普通损失时，我们才不需要改变输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e91c0ce8-c63f-4549-9d6b-336be3553e61",
      "metadata": {
        "id": "e91c0ce8-c63f-4549-9d6b-336be3553e61"
      },
      "outputs": [],
      "source": [
        "def hyperopt_objective(params):\n",
        "    \n",
        "    #定义评估器\n",
        "    #需要搜索的参数需要从输入的字典中索引出来\n",
        "    #不需要搜索的参数，可以是设置好的某个值\n",
        "    #在需要整数的参数前调整参数类型\n",
        "    reg = RFR(n_estimators = int(params[\"n_estimators\"])\n",
        "              ,max_depth = int(params[\"max_depth\"])\n",
        "              ,max_features = int(params[\"max_features\"])\n",
        "              ,min_impurity_decrease = params[\"min_impurity_decrease\"]\n",
        "              ,random_state=1412\n",
        "              ,verbose=False\n",
        "              ,n_jobs=-1)\n",
        "    \n",
        "    #交叉验证结果，输出负根均方误差（-RMSE）\n",
        "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
        "    validation_loss = cross_validate(reg,X,y\n",
        "                                     ,scoring=\"neg_root_mean_squared_error\"\n",
        "                                     ,cv=cv\n",
        "                                     ,verbose=False\n",
        "                                     ,n_jobs=-1\n",
        "                                     ,error_score='raise'\n",
        "                                    )\n",
        "    \n",
        "    #最终输出结果，由于只能取最小值，所以必须对（-RMSE）求绝对值\n",
        "    #以求解最小RMSE所对应的参数组合\n",
        "    return np.mean(abs(validation_loss[\"test_score\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "984ab68a-e892-46a6-8864-8279b502e203",
      "metadata": {
        "id": "984ab68a-e892-46a6-8864-8279b502e203"
      },
      "source": [
        "- 2 定义参数空间"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54c72a35-6f15-42b6-ac1b-76530ede5a73",
      "metadata": {
        "id": "54c72a35-6f15-42b6-ac1b-76530ede5a73"
      },
      "source": [
        "在任意超参数优化器中，优化器会将参数空格中的超参数组合作为备选组合，一组一组输入到算法中进行训练。在贝叶斯优化中，超参数组合会被输入我们定义好的目标函数$f(x)$中。\n",
        "\n",
        "在hyperopt中，我们使用特殊的字典形式来定义参数空间，其中键值对上的键可以任意设置，只要与目标函数中索引参数的键一致即可，键值对的值则是hyperopt独有的hp函数，包括了：\n",
        "\n",
        "> **hp.quniform(\"参数名称\", 下界, 上界, 步长)** - 适用于均匀分布的浮点数<br><br>\n",
        "> **hp.uniform(\"参数名称\",下界, 上界)** - 适用于随机分布的浮点数<br><br>\n",
        "> **hp.randint(\"参数名称\",上界)** - 适用于[0,上界)的整数，区间为前闭后开<br><br>\n",
        "> **hp.choice(\"参数名称\",[\"字符串1\",\"字符串2\",...])** - 适用于字符串类型，最优参数由索引表示<br><br>\n",
        "> **hp.choice(\"参数名称\",[\\*range(下界，上界，步长)])** - 适用于整数型，最优参数由索引表示<br><br>\n",
        "> **hp.choice(\"参数名称\",[整数1,整数2,整数3,...])** - 适用于整数型，最优参数由索引表示<br><br>\n",
        "> **hp.choice(\"参数名称\",[\"字符串1\",整数1,...])** - 适用于字符与整数混合，最优参数由索引表示\n",
        "\n",
        "在hyperopt的说明当中，并未明确参数取值范围空间的开闭，根据实验，如无特殊说明，hp中的参数空间定义方法应当都为前闭后开区间。我们依然使用在随机森林上获得最高分的随机搜索的参数空间："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84330b00-5020-49d2-a89b-1fe327743374",
      "metadata": {
        "id": "84330b00-5020-49d2-a89b-1fe327743374"
      },
      "outputs": [],
      "source": [
        "param_grid_simple = {'n_estimators': hp.quniform(\"n_estimators\",80,100,1)\n",
        "                     , 'max_depth': hp.quniform(\"max_depth\",10,25,1)\n",
        "                     , \"max_features\": hp.quniform(\"max_features\",10,20,1)\n",
        "                     , \"min_impurity_decrease\":hp.quniform(\"min_impurity_decrease\",0,5,1)\n",
        "                    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aadb180-9925-4c45-8f2a-c62e86c3fd34",
      "metadata": {
        "id": "1aadb180-9925-4c45-8f2a-c62e86c3fd34"
      },
      "source": [
        "由于hp.choice最终会返回最优参数的索引，容易与数值型参数的具体值混淆，而hp.randint又只能够支持从0开始进行计数，因此我们常常会使用quniform获得均匀分布的浮点数来替代整数。对于需要取整数的参数值，如果采用quniform方式构筑参数空间，则需要在目标函数中使用int函数限定输入类型。例如，在范围[0,5]中取值时，可以取出[0.0, 1.0, 2.0, 3.0,...]这种均匀浮点数，在输入目标函数时，则必须确保参数值前存在int函数。当然，如果使用hp.choice则不会存在该问题。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92c980d5-f5b4-43e7-b42b-f14b6a1a7ce7",
      "metadata": {
        "id": "92c980d5-f5b4-43e7-b42b-f14b6a1a7ce7"
      },
      "source": [
        "由于不涉及到连续型变量，因此我们可以计算出当前参数空间的大小："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9527fb3-ccc9-4592-a15f-97428322028c",
      "metadata": {
        "id": "d9527fb3-ccc9-4592-a15f-97428322028c",
        "outputId": "87b54661-283e-4eb8-86be-7097fc945f01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len([*range(80,100,1)])*len([*range(10,25,1)])*len([*range(10,20,1)])*len([range(0,5,1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fb6c73a-da2b-4004-a67d-406c61891e96",
      "metadata": {
        "id": "0fb6c73a-da2b-4004-a67d-406c61891e96"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3eda4e1-8433-4330-b4b7-8ccb7b2c4f39",
      "metadata": {
        "id": "a3eda4e1-8433-4330-b4b7-8ccb7b2c4f39"
      },
      "source": [
        "- 3 定义优化目标函数的具体流程"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7f7afd4-3f22-432a-b91e-b001b78934f1",
      "metadata": {
        "id": "d7f7afd4-3f22-432a-b91e-b001b78934f1"
      },
      "source": [
        "有了目标函数和参数空间，接下来我们就可以进行优化了。在Hyperopt中，我们用于优化的基础功能叫做fmin，在fmin中，我们可以自定义使用的代理模型（参数`algo`），一般来说我们有`tpe.suggest`以及`rand.suggest`两种选项，前者指代TPE方法，后者指代随机网格搜索方法。我们还可以通过partial功能来修改算法涉及到的具体参数，包括模型具体使用了多少个初始观测值（参数`n_start_jobs`），以及在计算采集函数值时究竟考虑多少个样本（参数`n_EI_candidates`）。当然，我们也可以不填写这些参数，就使用默认的参数值。\n",
        "\n",
        "除此之外，Hyperopt当中还有两个值得注意的功能，一个记录整个迭代过程的`trials`，另一个是提前停止参数`early_stop_fn`。其中，`trials`直译为“实验”或“测试”，表示我们不断尝试的每一种参数组合，这个参数中我们一般输入从hyperopt库中导入的方法Trials()，当优化完成之后，我们可以从保存好的trials中查看损失、参数等各种中间信息；而提前停止参数`early_stop_fn`中我们一般输入从hyperopt库导入的方法no_progress_loss()，这个方法中可以输入具体的数字n，表示当损失连续n次没有下降时，让算法提前停止。由于贝叶斯方法的随机性较高，当样本量不足时需要多次迭代才能够找到最优解，因此一般no_progress_loss()中的数值不会设置得太高。在我们的课程中，由于数据量较少，我设置了一个较高的值来避免迭代停止太早。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f5a94d-4631-41ac-91ef-a7581771aad0",
      "metadata": {
        "id": "04f5a94d-4631-41ac-91ef-a7581771aad0"
      },
      "outputs": [],
      "source": [
        "def param_hyperopt(max_evals=100):\n",
        "    \n",
        "    #保存迭代过程\n",
        "    trials = Trials()\n",
        "    \n",
        "    #设置提前停止\n",
        "    early_stop_fn = no_progress_loss(100)\n",
        "    \n",
        "    #定义代理模型\n",
        "    #algo = partial(tpe.suggest, n_startup_jobs=20, n_EI_candidates=50)\n",
        "    params_best = fmin(hyperopt_objective #目标函数\n",
        "                       , space = param_grid_simple #参数空间\n",
        "                       , algo = tpe.suggest #代理模型你要哪个呢？\n",
        "                       #, algo = algo\n",
        "                       , max_evals = max_evals #允许的迭代次数\n",
        "                       , verbose=True\n",
        "                       , trials = trials\n",
        "                       , early_stop_fn = early_stop_fn\n",
        "                      )\n",
        "    \n",
        "    #打印最优参数，fmin会自动打印最佳分数\n",
        "    print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
        "          \"\\n\")\n",
        "    return params_best, trials"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e1ba27-293c-46f3-be9d-f020ff2b7e2a",
      "metadata": {
        "id": "65e1ba27-293c-46f3-be9d-f020ff2b7e2a"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21d37b82-52f4-4bd9-be40-70d79c999853",
      "metadata": {
        "id": "21d37b82-52f4-4bd9-be40-70d79c999853"
      },
      "source": [
        "- 4 定义验证函数（非必要）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb7d8c9-1ef4-47b2-94de-2bb61d391554",
      "metadata": {
        "id": "abb7d8c9-1ef4-47b2-94de-2bb61d391554"
      },
      "outputs": [],
      "source": [
        "def hyperopt_validation(params):    \n",
        "    reg = RFR(n_estimators = int(params[\"n_estimators\"])\n",
        "              ,max_depth = int(params[\"max_depth\"])\n",
        "              ,max_features = int(params[\"max_features\"])\n",
        "              ,min_impurity_decrease = params[\"min_impurity_decrease\"]\n",
        "              ,random_state=1412\n",
        "              ,verbose=False\n",
        "              ,n_jobs=-1\n",
        "             )\n",
        "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
        "    validation_loss = cross_validate(reg,X,y\n",
        "                                     ,scoring=\"neg_root_mean_squared_error\"\n",
        "                                     ,cv=cv\n",
        "                                     ,verbose=False\n",
        "                                     ,n_jobs=-1\n",
        "                                    )\n",
        "    return np.mean(abs(validation_loss[\"test_score\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85cfee3f-8d56-403a-9e03-09b3173810eb",
      "metadata": {
        "id": "85cfee3f-8d56-403a-9e03-09b3173810eb"
      },
      "source": [
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "427a4f43-e979-4697-b7f6-6feadb82f681",
      "metadata": {
        "id": "427a4f43-e979-4697-b7f6-6feadb82f681"
      },
      "source": [
        "- 5 执行实际优化流程"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29f5425c-9a9a-4f25-9bb0-fc9d7b4a1d75",
      "metadata": {
        "id": "29f5425c-9a9a-4f25-9bb0-fc9d7b4a1d75",
        "outputId": "25500856-2b33-4c61-effa-ff5421206f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████████| 30/30 [00:06<00:00,  4.86trial/s, best loss: 28553.15406747252]\n",
            "\n",
            " \n",
            " best params:  {'max_depth': 23.0, 'max_features': 14.0, 'min_impurity_decrease': 1.0, 'n_estimators': 94.0} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "params_best, trials = param_hyperopt(30) #1%的空间大小"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06321ac6-6783-4e63-9161-0b9de3e9e2ea",
      "metadata": {
        "id": "06321ac6-6783-4e63-9161-0b9de3e9e2ea",
        "outputId": "18e018cf-6cf9-466e-baff-43f710f526bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████| 100/100 [00:21<00:00,  4.71trial/s, best loss: 28450.06487530331]\n",
            "\n",
            " \n",
            " best params:  {'max_depth': 22.0, 'max_features': 14.0, 'min_impurity_decrease': 0.0, 'n_estimators': 94.0} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "params_best, trials = param_hyperopt(100) #3%的空间大小"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51620547-45e4-4d5d-9a9a-8e97d0fbd714",
      "metadata": {
        "id": "51620547-45e4-4d5d-9a9a-8e97d0fbd714",
        "outputId": "3fd1a21a-1fc5-4380-8263-8c61c2a7684a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 92%|██████████████████████████████████████████▍   | 277/300 [01:01<00:05,  4.52trial/s, best loss: 28346.672687223065]\n",
            "\n",
            " \n",
            " best params:  {'max_depth': 22.0, 'max_features': 14.0, 'min_impurity_decrease': 0.0, 'n_estimators': 89.0} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "params_best, trials = param_hyperopt(300) #10%的空间大小"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f31596d-a1b4-4f98-8744-5a6291834e2c",
      "metadata": {
        "id": "8f31596d-a1b4-4f98-8744-5a6291834e2c",
        "outputId": "dd3b2fc4-d261-4cdc-8a07-090eb4c8547a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28346.672687223065"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hyperopt_validation(params_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "558187fe-07c4-4b1f-bef8-5bdcf39c7a62",
      "metadata": {
        "id": "558187fe-07c4-4b1f-bef8-5bdcf39c7a62",
        "outputId": "e4a76de1-0677-48da-e362-67e22946f7e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'state': 2,\n",
              " 'tid': 0,\n",
              " 'spec': None,\n",
              " 'result': {'loss': 28766.452192638408, 'status': 'ok'},\n",
              " 'misc': {'tid': 0,\n",
              "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
              "  'workdir': None,\n",
              "  'idxs': {'max_depth': [0],\n",
              "   'max_features': [0],\n",
              "   'min_impurity_decrease': [0],\n",
              "   'n_estimators': [0]},\n",
              "  'vals': {'max_depth': [13.0],\n",
              "   'max_features': [18.0],\n",
              "   'min_impurity_decrease': [4.0],\n",
              "   'n_estimators': [80.0]}},\n",
              " 'exp_key': None,\n",
              " 'owner': None,\n",
              " 'version': 0,\n",
              " 'book_time': datetime.datetime(2021, 12, 24, 13, 33, 19, 633000),\n",
              " 'refresh_time': datetime.datetime(2021, 12, 24, 13, 33, 19, 840000)}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#打印所有搜索相关的记录\n",
        "trials.trials[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e28038e3-e547-4d83-8637-37d23bccddbe",
      "metadata": {
        "id": "e28038e3-e547-4d83-8637-37d23bccddbe",
        "outputId": "0e5960f2-49a6-4519-8e94-711cebcb00d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[28766.452192638408,\n",
              " 29762.22885008687,\n",
              " 29233.57333898302,\n",
              " 29257.33343872428,\n",
              " 29180.63733732971,\n",
              " 29249.676793746046,\n",
              " 29309.41793204717,\n",
              " 28915.33638544984,\n",
              " 29122.269575607537,\n",
              " 29150.39720576636]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#打印全部搜索的目标函数值\n",
        "trials.losses()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e75fb1c-72cd-48c2-b506-75e56b3d41d2",
      "metadata": {
        "id": "6e75fb1c-72cd-48c2-b506-75e56b3d41d2"
      },
      "source": [
        "|HPO方法|默认参数|网格搜索|随机搜索|随机搜索<br>(大空间)|随机搜索<br>(连续型)|贝叶斯优化<br>(基于GP)|贝叶斯优化<br>(基于TPE)|\n",
        "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
        "|搜索空间/全域空间|-|1536/1536|800/1536|1536/3000|1536/无限|300/无限|277/3000|\n",
        "|运行时间（分钟）|-|6.36|<font color=\"green\">**2.83(↓)**</font>|<font color=\"green\">**3.86(↓)**</font>|3.92|<font color=\"green\">**2.11(↓)**</font>|<font color=\"green\">**1.00(↓)**</font>|\n",
        "|搜索最优（RMSE）|30571.266|29179.698|29251.284|<font color=\"green\">**29012.905(↓)**</font>|29148.381|<font color=\"green\">**28346.673(↓)**</font>|<font color=\"green\">**28346.673(-)**</font>|\n",
        "|重建最优（RMSE）|-|28572.070|<font color=\"brown\">**28639.969(↑)**</font>|<font color=\"green\">**28346.673(↓)**</font>|28495.682|<font color=\"green\">**28346.673(-)**</font>|<font color=\"green\">**28346.673(-)**</font>|"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f06da0ed-e706-4af4-846b-5a694c3544d4",
      "metadata": {
        "id": "f06da0ed-e706-4af4-846b-5a694c3544d4"
      },
      "source": [
        "由于具有提前停止功能，因此基于TPE的hyperopt优化可能在我们设置的迭代次数被达到之前就停止，也因此hyperopt迭代到实际最优值所需的迭代次数可能更少。同时，TPE方法相比于高斯过程计算会更加迅速，因此在运行277次迭代的情况下，hyperopt只需要1分钟时间，而运行300次迭代的bayes_opt却需要2.11分钟，可见，即便运行同样的迭代次数，hyperopt也是更有优势的，这或许是因为hyperopt的参数空间更加稀疏、在整数型参数搜索上更高效。\n",
        "\n",
        "不过HyperOpt的缺点也很明显，那就是代码精密度要求较高、灵活性较差，略微的改动就可能让代码疯狂报错难以跑通。同时，HyperOpt所支持的优化算法也不够多，如果我们专注地使用TPE方法，则掌握HyperOpt即可，如果我们希望拥有丰富的HPO手段，则可以更深入地接触Optuna库。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d194460-aed7-4575-8c03-2f8dfeedfc68",
      "metadata": {
        "id": "8d194460-aed7-4575-8c03-2f8dfeedfc68"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea27169b-9011-45a3-826b-e2cb23c6cc86",
      "metadata": {
        "tags": [],
        "id": "ea27169b-9011-45a3-826b-e2cb23c6cc86"
      },
      "source": [
        "## 3 基于Optuna实现多种贝叶斯优化"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15833a99-21be-471b-be39-e783973f478a",
      "metadata": {
        "id": "15833a99-21be-471b-be39-e783973f478a"
      },
      "source": [
        "Optuna是目前为止最为成熟、拓展性最强的超参数优化框架，与古旧的bayes_opt相比，Optuna明显是专门为机器学习和深度学习所设计。为了满足机器学习开发者的需求，Optuna拥有强大且固定的API，因此Optuna代码简单，编写高度模块化，是我们介绍的库中代码最为简练的库。Optuna的优势在于，它可以无缝衔接到PyTorch、Tensorflow等深度学习框架上，也可以与sklearn的优化库scikit-optimize结合使用，因此Optuna可以被用于各种各样的优化场景。在我们的课程中，我们将重点介绍Optuna实现贝叶斯优化的过程，其他优化方面内容可以参考以下页面：https://github.com/optuna/optuna 。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e166371-344c-4a62-b0ff-53984cc9df09",
      "metadata": {
        "id": "3e166371-344c-4a62-b0ff-53984cc9df09"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d1326e-8efe-47ce-b45b-c4c5068f34bb",
      "metadata": {
        "id": "43d1326e-8efe-47ce-b45b-c4c5068f34bb",
        "outputId": "bed49660-4b7d-403a-f596-e956688db9be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.10.0\n"
          ]
        }
      ],
      "source": [
        "print(optuna.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e92bf1a6-80c9-4f8b-afcf-fc49784b5379",
      "metadata": {
        "id": "e92bf1a6-80c9-4f8b-afcf-fc49784b5379"
      },
      "source": [
        "- 1 定义目标函数与参数空间"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86f15b56-a5a4-46e0-959e-17eed28cf48f",
      "metadata": {
        "id": "86f15b56-a5a4-46e0-959e-17eed28cf48f"
      },
      "source": [
        "Optuna的目标函数相当特别。在其他优化库中，我们需要单独输入参数或参数空间，优化器会在具体优化过程中将参数空间一一放入我们的目标函数进行优化，但在Optuna中，我们并不需要将参数或参数空间输入目标函数，而是需要**直接在目标函数中定义参数空间**。特别的是，Optuna优化器会生成一个指代备选参数的变量trial，该变量无法被用户获取或打开，但该变量在优化器中生存，并被输入目标函数。在目标函数中，我们可以通过变量trail所携带的方法来构造参数空间，具体如下所示："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b83ab0e-baf3-4d8b-9ef3-028fb6c41ddc",
      "metadata": {
        "id": "0b83ab0e-baf3-4d8b-9ef3-028fb6c41ddc"
      },
      "outputs": [],
      "source": [
        "def optuna_objective(trial):\n",
        "    \n",
        "    #定义参数空间\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\",80,100,1) #整数型，(参数名称，下界，上界，步长)\n",
        "    max_depth = trial.suggest_int(\"max_depth\",10,25,1)\n",
        "    max_features = trial.suggest_int(\"max_features\",10,20,1)\n",
        "    #max_features = trial.suggest_categorical(\"max_features\",[\"log2\",\"sqrt\",\"auto\"]) #字符型\n",
        "    min_impurity_decrease = trial.suggest_int(\"min_impurity_decrease\",0,5,1)\n",
        "    #min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) #浮点型\n",
        "    \n",
        "    #定义评估器\n",
        "    #需要优化的参数由上述参数空间决定\n",
        "    #不需要优化的参数则直接填写具体值\n",
        "    reg = RFR(n_estimators = n_estimators\n",
        "              ,max_depth = max_depth\n",
        "              ,max_features = max_features\n",
        "              ,min_impurity_decrease = min_impurity_decrease\n",
        "              ,random_state=1412\n",
        "              ,verbose=False\n",
        "              ,n_jobs=-1\n",
        "             )\n",
        "    \n",
        "    #交叉验证过程，输出负均方根误差(-RMSE)\n",
        "    #optuna同时支持最大化和最小化，因此如果输出-RMSE，则选择最大化\n",
        "    #如果选择输出RMSE，则选择最小化\n",
        "    cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
        "    validation_loss = cross_validate(reg,X,y\n",
        "                                     ,scoring=\"neg_root_mean_squared_error\"\n",
        "                                     ,cv=cv #交叉验证模式\n",
        "                                     ,verbose=False #是否打印进程\n",
        "                                     ,n_jobs=-1 #线程数\n",
        "                                     ,error_score='raise'\n",
        "                                    )\n",
        "    #最终输出RMSE\n",
        "    return np.mean(abs(validation_loss[\"test_score\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44c36597-cc45-4249-bf12-a450dfaf1cd3",
      "metadata": {
        "id": "44c36597-cc45-4249-bf12-a450dfaf1cd3"
      },
      "source": [
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24f7ee9-4c82-4c9a-96b0-55bffd003a41",
      "metadata": {
        "id": "e24f7ee9-4c82-4c9a-96b0-55bffd003a41"
      },
      "source": [
        "- 2 定义优化目标函数的具体流程"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b705ce71-0475-4932-a8ea-d859a70228b9",
      "metadata": {
        "id": "b705ce71-0475-4932-a8ea-d859a70228b9"
      },
      "source": [
        "在HyperOpt当中我们可以调整参数`algo`来自定义用于执行贝叶斯优化的具体算法，在Optuna中我们也可以。大部分备选的算法都集中在Optuna的模块sampler中，包括我们熟悉的TPE优化、随机网格搜索以及其他各类更加高级的贝叶斯过程，对于Optuna.sampler中调出的类，我们也可以直接输入参数来设置初始观测值的数量、以及每次计算采集函数时所考虑的观测值量。在Optuna库中并没有集成实现高斯过程的方法，但我们可以从scikit-optimize里面导入高斯过程来作为optuna中的`algo`设置，而具体的高斯过程相关的参数则可以通过如下方法进行设置："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caba8fb5-0555-4158-b22a-ef50df32c801",
      "metadata": {
        "id": "caba8fb5-0555-4158-b22a-ef50df32c801"
      },
      "outputs": [],
      "source": [
        "def optimizer_optuna(n_trials, algo):\n",
        "    \n",
        "    #定义使用TPE或者GP\n",
        "    if algo == \"TPE\":\n",
        "        algo = optuna.samplers.TPESampler(n_startup_trials = 10, n_ei_candidates = 24)\n",
        "    elif algo == \"GP\":\n",
        "        from optuna.integration import SkoptSampler\n",
        "        import skopt\n",
        "        algo = SkoptSampler(skopt_kwargs={'base_estimator':'GP', #选择高斯过程\n",
        "                                          'n_initial_points':10, #初始观测点10个\n",
        "                                          'acq_func':'EI'} #选择的采集函数为EI，期望增量\n",
        "                           )\n",
        "    \n",
        "    #实际优化过程，首先实例化优化器\n",
        "    study = optuna.create_study(sampler = algo #要使用的具体算法\n",
        "                                , direction=\"minimize\" #优化的方向，可以填写minimize或maximize\n",
        "                               )\n",
        "    #开始优化，n_trials为允许的最大迭代次数\n",
        "    #由于参数空间已经在目标函数中定义好，因此不需要输入参数空间\n",
        "    study.optimize(optuna_objective #目标函数\n",
        "                   , n_trials=n_trials #最大迭代次数（包括最初的观测值的）\n",
        "                   , show_progress_bar=True #要不要展示进度条呀？\n",
        "                  )\n",
        "    \n",
        "    #可直接从优化好的对象study中调用优化的结果\n",
        "    #打印最佳参数与最佳损失值\n",
        "    print(\"\\n\",\"\\n\",\"best params: \", study.best_trial.params,\n",
        "          \"\\n\",\"\\n\",\"best score: \", study.best_trial.values,\n",
        "          \"\\n\")\n",
        "    \n",
        "    return study.best_trial.params, study.best_trial.values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2efa533b-c099-43c8-a480-2239e4e2d7e2",
      "metadata": {
        "id": "2efa533b-c099-43c8-a480-2239e4e2d7e2"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb2e68dc-4628-41a5-bc9e-60604d4de1a5",
      "metadata": {
        "id": "cb2e68dc-4628-41a5-bc9e-60604d4de1a5"
      },
      "source": [
        "- 3 执行实际优化流程"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d2167f6-d691-4fe3-beb1-01eed08df1ee",
      "metadata": {
        "id": "6d2167f6-d691-4fe3-beb1-01eed08df1ee"
      },
      "source": [
        "Optuna库虽然是当今最为成熟的HPO方法之一，但当参数空间较小时，Optuna库在迭代中容易出现抽样BUG，**即Optuna会持续抽到曾经被抽到过的参数组合**，并且持续报警告说\"算法已在这个参数组合上检验过目标函数了\"。在实际迭代过程中，一旦出现这个Bug，那当下的迭代就无用了，因为已经检验过的观测值不会对优化有任何的帮助，因此对损失的优化将会停止。如果出现该BUG，则可以增大参数空间的范围或密度。或者使用如下的代码令警告关闭："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "612039b7-7314-4d0e-b7aa-7fed52f4a095",
      "metadata": {
        "id": "612039b7-7314-4d0e-b7aa-7fed52f4a095"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b44bad9e-3156-4ad3-9f49-f866dc49add4",
      "metadata": {
        "id": "b44bad9e-3156-4ad3-9f49-f866dc49add4",
        "outputId": "5f373c6f-1375-4586-e6eb-a03a5465d168",
        "colab": {
          "referenced_widgets": [
            "f9b326e4f70e4f219a257ce3d279ef47"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-12-24 22:14:26,709]\u001b[0m A new study created in memory with name: no-name-05950945-f6f7-41c3-bd8a-ffb15a284ea9\u001b[0m\n",
            "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
            "  self._init_valid()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9b326e4f70e4f219a257ce3d279ef47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-12-24 22:14:28,229]\u001b[0m Trial 0 finished with value: 28848.70339210933 and parameters: {'n_estimators': 99, 'max_depth': 14, 'max_features': 16, 'min_impurity_decrease': 4}. Best is trial 0 with value: 28848.70339210933.\u001b[0m\n",
            "\u001b[32m[I 2021-12-24 22:14:29,309]\u001b[0m Trial 1 finished with value: 28632.395126147465 and parameters: {'n_estimators': 90, 'max_depth': 23, 'max_features': 16, 'min_impurity_decrease': 2}. Best is trial 1 with value: 28632.395126147465.\u001b[0m\n",
            "\u001b[32m[I 2021-12-24 22:14:30,346]\u001b[0m Trial 2 finished with value: 29301.159287113685 and parameters: {'n_estimators': 89, 'max_depth': 17, 'max_features': 12, 'min_impurity_decrease': 0}. Best is trial 1 with value: 28632.395126147465.\u001b[0m\n",
            "\u001b[32m[I 2021-12-24 22:14:31,215]\u001b[0m Trial 3 finished with value: 29756.446415640086 and parameters: {'n_estimators': 80, 'max_depth': 11, 'max_features': 14, 'min_impurity_decrease': 3}. Best is trial 1 with value: 28632.395126147465.\u001b[0m\n",
            "\u001b[32m[I 2021-12-24 22:14:31,439]\u001b[0m Trial 4 finished with value: 29784.547574554617 and parameters: {'n_estimators': 88, 'max_depth': 11, 'max_features': 15, 'min_impurity_decrease': 2}. Best is trial 1 with value: 28632.395126147465.\u001b[0m\n",
            "\u001b[32m[I 2021-12-24 22:14:31,651]\u001b[0m Trial 5 finished with value: 28854.291800282757 and parameters: {'n_estimators': 82, 'max_depth': 12, 'max_features': 18, 'min_impurity_decrease': 3}. Best is trial 1 with value: 28632.395126147465.\u001b[0m\n",
            "\u001b[32m[I 2021-12-24 22:14:31,853]\u001b[0m Trial 6 finished with value: 29268.28890743908 and parameters: {'n_estimators': 80, 'max_depth': 10, 'max_features': 19, 'min_impurity_decrease': 5}. Best is trial 1 with value: 28632.395126147465.\u001b[0m\n",
            "\u001b[32m[I 2021-12-24 22:14:32,111]\u001b[0m Trial 7 finished with value: 29302.5258321895 and parameters: {'n_estimators': 99, 'max_depth': 16, 'max_features': 14, 'min_impurity_decrease': 3}. Best is trial 1 with value: 28632.395126147465.\u001b[0m\n",
            "\u001b[32m[I 2021-12-24 22:14:32,353]\u001b[0m Trial 8 finished with value: 29449.903990989755 and parameters: {'n_estimators': 80, 'max_depth': 21, 'max_features': 17, 'min_impurity_decrease': 1}. Best is trial 1 with value: 28632.395126147465.\u001b[0m\n",
            "\u001b[32m[I 2021-12-24 22:14:32,737]\u001b[0m Trial 9 finished with value: 29168.76064401323 and parameters: {'n_estimators': 97, 'max_depth': 22, 'max_features': 17, 'min_impurity_decrease': 1}. Best is trial 1 with value: 28632.395126147465.\u001b[0m\n",
            "\n",
            " \n",
            " best params:  {'n_estimators': 90, 'max_depth': 23, 'max_features': 16, 'min_impurity_decrease': 2} \n",
            " \n",
            " best score:  [28632.395126147465] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_params, best_score = optimizer_optuna(10,\"GP\") #默认打印迭代过程"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "954c4773-5d65-448c-a2e7-b1aabbdc39b5",
      "metadata": {
        "id": "954c4773-5d65-448c-a2e7-b1aabbdc39b5",
        "outputId": "f5d65be5-3749-4b36-acbf-9d0357104269",
        "colab": {
          "referenced_widgets": [
            "9d815025b60d476897d7693d177c46e6"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
            "  self._init_valid()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d815025b60d476897d7693d177c46e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " best params:  {'n_estimators': 96, 'max_depth': 22, 'max_features': 14, 'min_impurity_decrease': 3} \n",
            " \n",
            " best score:  [28457.22400533479] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.ERROR) #关闭自动打印的info，只显示进度条\n",
        "#optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "best_params, best_score = optimizer_optuna(300,\"TPE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b48a61f-3999-4bca-b7f7-46d949f494ff",
      "metadata": {
        "id": "5b48a61f-3999-4bca-b7f7-46d949f494ff",
        "outputId": "8207c22f-a0c6-45b6-f638-70f49f637feb",
        "colab": {
          "referenced_widgets": [
            "4a8de09b52914e82838a6908cb5003f7"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
            "  self._init_valid()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a8de09b52914e82838a6908cb5003f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " best params:  {'n_estimators': 87, 'max_depth': 23, 'max_features': 16, 'min_impurity_decrease': 5} \n",
            " \n",
            " best score:  [28541.05837443567] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
        "best_params, best_score = optimizer_optuna(300,\"GP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76794448-089e-4513-8d08-8162df39c1f7",
      "metadata": {
        "id": "76794448-089e-4513-8d08-8162df39c1f7"
      },
      "source": [
        "很显然，基于高斯过程的贝叶斯优化是比基于TPE的贝叶斯优化运行更加缓慢的。在Optuna进行调试时，我并没有多次运行并取出Optuna表现最好的值，因此我们可以不将Optuna的结果最终放入表格进行比较，不过在TPE模式下，其运行速度与HyperOpt的运行速度高度接近。在未来的课程中，除非特殊说明，我们将默认使用TPE方法进行优化。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ad6f626-8c18-437a-b96f-95a25233d940",
      "metadata": {
        "id": "1ad6f626-8c18-437a-b96f-95a25233d940"
      },
      "source": [
        "  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Lesson 10.2 超参数优化算法 - 贝叶斯优化（1223）.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}